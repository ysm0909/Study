{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2926c9c0-55f7-470f-8c7d-dcc984210f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\유승미\\AppData\\Local\\Temp\\ipykernel_10796\\4225343611.py:5: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리를 불러들임 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84a5b0e-4706-4911-abaf-126de1ac24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe447cb-790d-49a4-a9ab-ffe02254b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\유승미\\AppData\\Local\\Temp\\ipykernel_24464\\1264417815.py:124: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.585161, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 3.242548, Training Accuracy= 0.12109\n",
      "Iter 20, Minibatch Loss= 2.505862, Training Accuracy= 0.23047\n",
      "Iter 30, Minibatch Loss= 2.045961, Training Accuracy= 0.34766\n",
      "Iter 40, Minibatch Loss= 1.752605, Training Accuracy= 0.39062\n",
      "Iter 50, Minibatch Loss= 1.888240, Training Accuracy= 0.35156\n",
      "Iter 60, Minibatch Loss= 1.746933, Training Accuracy= 0.41797\n",
      "Iter 70, Minibatch Loss= 1.620615, Training Accuracy= 0.44141\n",
      "Iter 80, Minibatch Loss= 1.484982, Training Accuracy= 0.50000\n",
      "Iter 90, Minibatch Loss= 1.473826, Training Accuracy= 0.47656\n",
      "Iter 100, Minibatch Loss= 1.450370, Training Accuracy= 0.47656\n",
      "Iter 110, Minibatch Loss= 1.482732, Training Accuracy= 0.51172\n",
      "Iter 120, Minibatch Loss= 1.312930, Training Accuracy= 0.51953\n",
      "Iter 130, Minibatch Loss= 1.357566, Training Accuracy= 0.54297\n",
      "Iter 140, Minibatch Loss= 1.393715, Training Accuracy= 0.48828\n",
      "Iter 150, Minibatch Loss= 1.295688, Training Accuracy= 0.51562\n",
      "Iter 160, Minibatch Loss= 1.295795, Training Accuracy= 0.53516\n",
      "Iter 170, Minibatch Loss= 1.282699, Training Accuracy= 0.53906\n",
      "Iter 180, Minibatch Loss= 1.322339, Training Accuracy= 0.58203\n",
      "Iter 190, Minibatch Loss= 1.208529, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5667\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.724392, Training Accuracy= 0.14844\n",
      "Iter 10, Minibatch Loss= 4.185298, Training Accuracy= 0.19922\n",
      "Iter 20, Minibatch Loss= 2.486769, Training Accuracy= 0.22266\n",
      "Iter 30, Minibatch Loss= 2.033270, Training Accuracy= 0.31641\n",
      "Iter 40, Minibatch Loss= 1.638793, Training Accuracy= 0.45703\n",
      "Iter 50, Minibatch Loss= 1.662863, Training Accuracy= 0.45312\n",
      "Iter 60, Minibatch Loss= 1.464444, Training Accuracy= 0.51172\n",
      "Iter 70, Minibatch Loss= 1.401147, Training Accuracy= 0.55859\n",
      "Iter 80, Minibatch Loss= 1.373972, Training Accuracy= 0.55859\n",
      "Iter 90, Minibatch Loss= 1.274684, Training Accuracy= 0.54688\n",
      "Iter 100, Minibatch Loss= 1.517840, Training Accuracy= 0.51172\n",
      "Iter 110, Minibatch Loss= 1.214274, Training Accuracy= 0.60547\n",
      "Iter 120, Minibatch Loss= 1.275037, Training Accuracy= 0.55469\n",
      "Iter 130, Minibatch Loss= 1.215731, Training Accuracy= 0.60938\n",
      "Iter 140, Minibatch Loss= 1.225735, Training Accuracy= 0.56641\n",
      "Iter 150, Minibatch Loss= 1.243892, Training Accuracy= 0.56641\n",
      "Iter 160, Minibatch Loss= 1.112333, Training Accuracy= 0.64453\n",
      "Iter 170, Minibatch Loss= 1.297836, Training Accuracy= 0.53516\n",
      "Iter 180, Minibatch Loss= 1.241618, Training Accuracy= 0.57422\n",
      "Iter 190, Minibatch Loss= 1.321311, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5922\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.176696, Training Accuracy= 0.12109\n",
      "Iter 10, Minibatch Loss= 2.701564, Training Accuracy= 0.15625\n",
      "Iter 20, Minibatch Loss= 2.177861, Training Accuracy= 0.28516\n",
      "Iter 30, Minibatch Loss= 2.037841, Training Accuracy= 0.35938\n",
      "Iter 40, Minibatch Loss= 1.646600, Training Accuracy= 0.45703\n",
      "Iter 50, Minibatch Loss= 1.592599, Training Accuracy= 0.45312\n",
      "Iter 60, Minibatch Loss= 1.556068, Training Accuracy= 0.44531\n",
      "Iter 70, Minibatch Loss= 1.475355, Training Accuracy= 0.48438\n",
      "Iter 80, Minibatch Loss= 1.339678, Training Accuracy= 0.53906\n",
      "Iter 90, Minibatch Loss= 1.506349, Training Accuracy= 0.45312\n",
      "Iter 100, Minibatch Loss= 1.405538, Training Accuracy= 0.47266\n",
      "Iter 110, Minibatch Loss= 1.270125, Training Accuracy= 0.58203\n",
      "Iter 120, Minibatch Loss= 1.215877, Training Accuracy= 0.55859\n",
      "Iter 130, Minibatch Loss= 1.386514, Training Accuracy= 0.52734\n",
      "Iter 140, Minibatch Loss= 1.214568, Training Accuracy= 0.54688\n",
      "Iter 150, Minibatch Loss= 1.252848, Training Accuracy= 0.56250\n",
      "Iter 160, Minibatch Loss= 1.191179, Training Accuracy= 0.57422\n",
      "Iter 170, Minibatch Loss= 1.142986, Training Accuracy= 0.61719\n",
      "Iter 180, Minibatch Loss= 1.125053, Training Accuracy= 0.60938\n",
      "Iter 190, Minibatch Loss= 1.204754, Training Accuracy= 0.57031\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5903\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 3.907863, Training Accuracy= 0.12891\n",
      "Iter 10, Minibatch Loss= 2.298371, Training Accuracy= 0.30078\n",
      "Iter 20, Minibatch Loss= 1.800580, Training Accuracy= 0.43359\n",
      "Iter 30, Minibatch Loss= 1.661764, Training Accuracy= 0.41797\n",
      "Iter 40, Minibatch Loss= 1.675467, Training Accuracy= 0.45703\n",
      "Iter 50, Minibatch Loss= 1.377723, Training Accuracy= 0.53125\n",
      "Iter 60, Minibatch Loss= 1.395103, Training Accuracy= 0.55078\n",
      "Iter 70, Minibatch Loss= 1.245966, Training Accuracy= 0.57031\n",
      "Iter 80, Minibatch Loss= 1.477006, Training Accuracy= 0.48828\n",
      "Iter 90, Minibatch Loss= 1.197938, Training Accuracy= 0.60156\n",
      "Iter 100, Minibatch Loss= 1.212039, Training Accuracy= 0.58594\n",
      "Iter 110, Minibatch Loss= 1.144798, Training Accuracy= 0.58594\n",
      "Iter 120, Minibatch Loss= 1.228593, Training Accuracy= 0.55078\n",
      "Iter 130, Minibatch Loss= 1.107845, Training Accuracy= 0.62500\n",
      "Iter 140, Minibatch Loss= 1.127070, Training Accuracy= 0.62500\n",
      "Iter 150, Minibatch Loss= 0.993745, Training Accuracy= 0.66016\n",
      "Iter 160, Minibatch Loss= 1.078251, Training Accuracy= 0.60156\n",
      "Iter 170, Minibatch Loss= 1.220078, Training Accuracy= 0.62109\n",
      "Iter 180, Minibatch Loss= 1.003944, Training Accuracy= 0.62109\n",
      "Iter 190, Minibatch Loss= 1.079654, Training Accuracy= 0.64844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.648\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_7:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.754632, Training Accuracy= 0.08203\n",
      "Iter 10, Minibatch Loss= 3.444642, Training Accuracy= 0.11328\n",
      "Iter 20, Minibatch Loss= 2.641234, Training Accuracy= 0.17188\n",
      "Iter 30, Minibatch Loss= 2.220244, Training Accuracy= 0.26953\n",
      "Iter 40, Minibatch Loss= 2.013244, Training Accuracy= 0.32031\n",
      "Iter 50, Minibatch Loss= 1.635263, Training Accuracy= 0.42188\n",
      "Iter 60, Minibatch Loss= 1.367945, Training Accuracy= 0.51953\n",
      "Iter 70, Minibatch Loss= 1.534267, Training Accuracy= 0.48828\n",
      "Iter 80, Minibatch Loss= 1.463713, Training Accuracy= 0.46484\n",
      "Iter 90, Minibatch Loss= 1.534910, Training Accuracy= 0.45703\n",
      "Iter 100, Minibatch Loss= 1.259631, Training Accuracy= 0.59375\n",
      "Iter 110, Minibatch Loss= 1.400644, Training Accuracy= 0.53516\n",
      "Iter 120, Minibatch Loss= 1.286009, Training Accuracy= 0.51562\n",
      "Iter 130, Minibatch Loss= 1.348528, Training Accuracy= 0.53125\n",
      "Iter 140, Minibatch Loss= 1.279969, Training Accuracy= 0.54688\n",
      "Iter 150, Minibatch Loss= 1.257901, Training Accuracy= 0.52344\n",
      "Iter 160, Minibatch Loss= 1.125945, Training Accuracy= 0.59375\n",
      "Iter 170, Minibatch Loss= 1.201979, Training Accuracy= 0.60547\n",
      "Iter 180, Minibatch Loss= 1.228765, Training Accuracy= 0.59375\n",
      "Iter 190, Minibatch Loss= 1.234438, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6054\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_9:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.720268, Training Accuracy= 0.21875\n",
      "Iter 10, Minibatch Loss= 3.178483, Training Accuracy= 0.22266\n",
      "Iter 20, Minibatch Loss= 2.573754, Training Accuracy= 0.29297\n",
      "Iter 30, Minibatch Loss= 2.046178, Training Accuracy= 0.37891\n",
      "Iter 40, Minibatch Loss= 1.733997, Training Accuracy= 0.38672\n",
      "Iter 50, Minibatch Loss= 1.646851, Training Accuracy= 0.43359\n",
      "Iter 60, Minibatch Loss= 1.461399, Training Accuracy= 0.52344\n",
      "Iter 70, Minibatch Loss= 1.501777, Training Accuracy= 0.48047\n",
      "Iter 80, Minibatch Loss= 1.292870, Training Accuracy= 0.55078\n",
      "Iter 90, Minibatch Loss= 1.248856, Training Accuracy= 0.56641\n",
      "Iter 100, Minibatch Loss= 1.318970, Training Accuracy= 0.57422\n",
      "Iter 110, Minibatch Loss= 1.466021, Training Accuracy= 0.52344\n",
      "Iter 120, Minibatch Loss= 1.260489, Training Accuracy= 0.58203\n",
      "Iter 130, Minibatch Loss= 1.260188, Training Accuracy= 0.58984\n",
      "Iter 140, Minibatch Loss= 1.305787, Training Accuracy= 0.53906\n",
      "Iter 150, Minibatch Loss= 1.053472, Training Accuracy= 0.64844\n",
      "Iter 160, Minibatch Loss= 1.210116, Training Accuracy= 0.58984\n",
      "Iter 170, Minibatch Loss= 1.021984, Training Accuracy= 0.65234\n",
      "Iter 180, Minibatch Loss= 1.078158, Training Accuracy= 0.63672\n",
      "Iter 190, Minibatch Loss= 1.100998, Training Accuracy= 0.58984\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.63\n",
      "Hidden Layer 2 Nodes: 128 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_11:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.416573, Training Accuracy= 0.23828\n",
      "Iter 10, Minibatch Loss= 3.100154, Training Accuracy= 0.14062\n",
      "Iter 20, Minibatch Loss= 2.266237, Training Accuracy= 0.30469\n",
      "Iter 30, Minibatch Loss= 1.719177, Training Accuracy= 0.42188\n",
      "Iter 40, Minibatch Loss= 1.601878, Training Accuracy= 0.46484\n",
      "Iter 50, Minibatch Loss= 1.414829, Training Accuracy= 0.50781\n",
      "Iter 60, Minibatch Loss= 1.281431, Training Accuracy= 0.55859\n",
      "Iter 70, Minibatch Loss= 1.276849, Training Accuracy= 0.55859\n",
      "Iter 80, Minibatch Loss= 1.232927, Training Accuracy= 0.58594\n",
      "Iter 90, Minibatch Loss= 1.337116, Training Accuracy= 0.55859\n",
      "Iter 100, Minibatch Loss= 1.218727, Training Accuracy= 0.60156\n",
      "Iter 110, Minibatch Loss= 1.259351, Training Accuracy= 0.55469\n",
      "Iter 120, Minibatch Loss= 1.161162, Training Accuracy= 0.62891\n",
      "Iter 130, Minibatch Loss= 1.157293, Training Accuracy= 0.60547\n",
      "Iter 140, Minibatch Loss= 1.185884, Training Accuracy= 0.60156\n",
      "Iter 150, Minibatch Loss= 1.231777, Training Accuracy= 0.57031\n",
      "Iter 160, Minibatch Loss= 1.224782, Training Accuracy= 0.60156\n",
      "Iter 170, Minibatch Loss= 1.346380, Training Accuracy= 0.53125\n",
      "Iter 180, Minibatch Loss= 1.281257, Training Accuracy= 0.56250\n",
      "Iter 190, Minibatch Loss= 1.226431, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5961\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_13:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.593145, Training Accuracy= 0.06641\n",
      "Iter 10, Minibatch Loss= 2.683193, Training Accuracy= 0.33594\n",
      "Iter 20, Minibatch Loss= 2.030481, Training Accuracy= 0.30078\n",
      "Iter 30, Minibatch Loss= 1.625322, Training Accuracy= 0.41797\n",
      "Iter 40, Minibatch Loss= 1.589363, Training Accuracy= 0.51172\n",
      "Iter 50, Minibatch Loss= 1.335421, Training Accuracy= 0.56250\n",
      "Iter 60, Minibatch Loss= 1.438284, Training Accuracy= 0.50391\n",
      "Iter 70, Minibatch Loss= 1.310910, Training Accuracy= 0.56641\n",
      "Iter 80, Minibatch Loss= 1.153039, Training Accuracy= 0.58594\n",
      "Iter 90, Minibatch Loss= 1.137289, Training Accuracy= 0.61719\n",
      "Iter 100, Minibatch Loss= 1.204283, Training Accuracy= 0.62891\n",
      "Iter 110, Minibatch Loss= 1.240122, Training Accuracy= 0.54688\n",
      "Iter 120, Minibatch Loss= 1.144523, Training Accuracy= 0.63281\n",
      "Iter 130, Minibatch Loss= 1.205680, Training Accuracy= 0.60547\n",
      "Iter 140, Minibatch Loss= 1.097984, Training Accuracy= 0.64062\n",
      "Iter 150, Minibatch Loss= 1.090386, Training Accuracy= 0.60547\n",
      "Iter 160, Minibatch Loss= 1.097680, Training Accuracy= 0.60156\n",
      "Iter 170, Minibatch Loss= 1.091343, Training Accuracy= 0.60156\n",
      "Iter 180, Minibatch Loss= 1.143728, Training Accuracy= 0.62891\n",
      "Iter 190, Minibatch Loss= 1.095196, Training Accuracy= 0.62109\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.628\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_15:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.137779, Training Accuracy= 0.10938\n",
      "Iter 10, Minibatch Loss= 3.102036, Training Accuracy= 0.15625\n",
      "Iter 20, Minibatch Loss= 2.443486, Training Accuracy= 0.18750\n",
      "Iter 30, Minibatch Loss= 1.890761, Training Accuracy= 0.41016\n",
      "Iter 40, Minibatch Loss= 1.710940, Training Accuracy= 0.45312\n",
      "Iter 50, Minibatch Loss= 1.680766, Training Accuracy= 0.47266\n",
      "Iter 60, Minibatch Loss= 1.484838, Training Accuracy= 0.46484\n",
      "Iter 70, Minibatch Loss= 1.392287, Training Accuracy= 0.47656\n",
      "Iter 80, Minibatch Loss= 1.217035, Training Accuracy= 0.58203\n",
      "Iter 90, Minibatch Loss= 1.324808, Training Accuracy= 0.57812\n",
      "Iter 100, Minibatch Loss= 1.260382, Training Accuracy= 0.58984\n",
      "Iter 110, Minibatch Loss= 1.187314, Training Accuracy= 0.59766\n",
      "Iter 120, Minibatch Loss= 1.166592, Training Accuracy= 0.60156\n",
      "Iter 130, Minibatch Loss= 1.204782, Training Accuracy= 0.57812\n",
      "Iter 140, Minibatch Loss= 1.182266, Training Accuracy= 0.60938\n",
      "Iter 150, Minibatch Loss= 1.191183, Training Accuracy= 0.58203\n",
      "Iter 160, Minibatch Loss= 1.126154, Training Accuracy= 0.58594\n",
      "Iter 170, Minibatch Loss= 1.146926, Training Accuracy= 0.58203\n",
      "Iter 180, Minibatch Loss= 1.218068, Training Accuracy= 0.58203\n",
      "Iter 190, Minibatch Loss= 1.102711, Training Accuracy= 0.60547\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6167\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_17:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.823696, Training Accuracy= 0.10938\n",
      "Iter 10, Minibatch Loss= 2.600627, Training Accuracy= 0.20703\n",
      "Iter 20, Minibatch Loss= 2.211204, Training Accuracy= 0.29688\n",
      "Iter 30, Minibatch Loss= 1.708166, Training Accuracy= 0.40234\n",
      "Iter 40, Minibatch Loss= 1.574965, Training Accuracy= 0.44141\n",
      "Iter 50, Minibatch Loss= 1.543268, Training Accuracy= 0.49609\n",
      "Iter 60, Minibatch Loss= 1.434855, Training Accuracy= 0.51953\n",
      "Iter 70, Minibatch Loss= 1.568806, Training Accuracy= 0.45312\n",
      "Iter 80, Minibatch Loss= 1.341748, Training Accuracy= 0.56250\n",
      "Iter 90, Minibatch Loss= 1.156276, Training Accuracy= 0.62500\n",
      "Iter 100, Minibatch Loss= 1.141072, Training Accuracy= 0.63281\n",
      "Iter 110, Minibatch Loss= 1.214602, Training Accuracy= 0.58984\n",
      "Iter 120, Minibatch Loss= 1.267181, Training Accuracy= 0.58594\n",
      "Iter 130, Minibatch Loss= 1.132707, Training Accuracy= 0.61328\n",
      "Iter 140, Minibatch Loss= 1.065993, Training Accuracy= 0.60547\n",
      "Iter 150, Minibatch Loss= 1.226050, Training Accuracy= 0.57422\n",
      "Iter 160, Minibatch Loss= 1.234909, Training Accuracy= 0.58984\n",
      "Iter 170, Minibatch Loss= 0.993619, Training Accuracy= 0.66797\n",
      "Iter 180, Minibatch Loss= 1.177360, Training Accuracy= 0.58203\n",
      "Iter 190, Minibatch Loss= 1.079239, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.618\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_19:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.260777, Training Accuracy= 0.10938\n",
      "Iter 10, Minibatch Loss= 2.610138, Training Accuracy= 0.17188\n",
      "Iter 20, Minibatch Loss= 2.062456, Training Accuracy= 0.33594\n",
      "Iter 30, Minibatch Loss= 1.771991, Training Accuracy= 0.40625\n",
      "Iter 40, Minibatch Loss= 1.606616, Training Accuracy= 0.46484\n",
      "Iter 50, Minibatch Loss= 1.475965, Training Accuracy= 0.48047\n",
      "Iter 60, Minibatch Loss= 1.336341, Training Accuracy= 0.53906\n",
      "Iter 70, Minibatch Loss= 1.423455, Training Accuracy= 0.51172\n",
      "Iter 80, Minibatch Loss= 1.321632, Training Accuracy= 0.56250\n",
      "Iter 90, Minibatch Loss= 1.297442, Training Accuracy= 0.53906\n",
      "Iter 100, Minibatch Loss= 1.162612, Training Accuracy= 0.59375\n",
      "Iter 110, Minibatch Loss= 1.402000, Training Accuracy= 0.54688\n",
      "Iter 120, Minibatch Loss= 1.222012, Training Accuracy= 0.58203\n",
      "Iter 130, Minibatch Loss= 1.077597, Training Accuracy= 0.64844\n",
      "Iter 140, Minibatch Loss= 1.124548, Training Accuracy= 0.62109\n",
      "Iter 150, Minibatch Loss= 1.065917, Training Accuracy= 0.60547\n",
      "Iter 160, Minibatch Loss= 1.247057, Training Accuracy= 0.58203\n",
      "Iter 170, Minibatch Loss= 1.067554, Training Accuracy= 0.62500\n",
      "Iter 180, Minibatch Loss= 0.944540, Training Accuracy= 0.67188\n",
      "Iter 190, Minibatch Loss= 1.116815, Training Accuracy= 0.58984\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6453\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_21:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.706305, Training Accuracy= 0.07812\n",
      "Iter 10, Minibatch Loss= 3.528799, Training Accuracy= 0.17188\n",
      "Iter 20, Minibatch Loss= 2.391122, Training Accuracy= 0.26953\n",
      "Iter 30, Minibatch Loss= 1.849642, Training Accuracy= 0.35547\n",
      "Iter 40, Minibatch Loss= 1.689686, Training Accuracy= 0.42578\n",
      "Iter 50, Minibatch Loss= 1.504181, Training Accuracy= 0.52734\n",
      "Iter 60, Minibatch Loss= 1.351432, Training Accuracy= 0.56250\n",
      "Iter 70, Minibatch Loss= 1.255557, Training Accuracy= 0.59766\n",
      "Iter 80, Minibatch Loss= 1.154992, Training Accuracy= 0.60938\n",
      "Iter 90, Minibatch Loss= 1.161938, Training Accuracy= 0.58203\n",
      "Iter 100, Minibatch Loss= 1.166232, Training Accuracy= 0.57422\n",
      "Iter 110, Minibatch Loss= 1.188272, Training Accuracy= 0.55078\n",
      "Iter 120, Minibatch Loss= 1.152961, Training Accuracy= 0.62500\n",
      "Iter 130, Minibatch Loss= 1.086178, Training Accuracy= 0.62109\n",
      "Iter 140, Minibatch Loss= 1.148076, Training Accuracy= 0.60547\n",
      "Iter 150, Minibatch Loss= 1.088610, Training Accuracy= 0.63281\n",
      "Iter 160, Minibatch Loss= 0.916724, Training Accuracy= 0.67969\n",
      "Iter 170, Minibatch Loss= 1.085727, Training Accuracy= 0.66016\n",
      "Iter 180, Minibatch Loss= 1.061998, Training Accuracy= 0.62500\n",
      "Iter 190, Minibatch Loss= 0.988442, Training Accuracy= 0.66797\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6505\n",
      "Hidden Layer 2 Nodes: 192 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_23:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.109402, Training Accuracy= 0.11328\n",
      "Iter 10, Minibatch Loss= 2.826298, Training Accuracy= 0.16797\n",
      "Iter 20, Minibatch Loss= 2.351846, Training Accuracy= 0.28906\n",
      "Iter 30, Minibatch Loss= 1.977789, Training Accuracy= 0.35156\n",
      "Iter 40, Minibatch Loss= 1.753741, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.531309, Training Accuracy= 0.48438\n",
      "Iter 60, Minibatch Loss= 1.484730, Training Accuracy= 0.51172\n",
      "Iter 70, Minibatch Loss= 1.395057, Training Accuracy= 0.53906\n",
      "Iter 80, Minibatch Loss= 1.324192, Training Accuracy= 0.54688\n",
      "Iter 90, Minibatch Loss= 1.248726, Training Accuracy= 0.56641\n",
      "Iter 100, Minibatch Loss= 1.152325, Training Accuracy= 0.60938\n",
      "Iter 110, Minibatch Loss= 1.207155, Training Accuracy= 0.58203\n",
      "Iter 120, Minibatch Loss= 1.215287, Training Accuracy= 0.59375\n",
      "Iter 130, Minibatch Loss= 1.286389, Training Accuracy= 0.53516\n",
      "Iter 140, Minibatch Loss= 1.241489, Training Accuracy= 0.54688\n",
      "Iter 150, Minibatch Loss= 1.121219, Training Accuracy= 0.66016\n",
      "Iter 160, Minibatch Loss= 1.180954, Training Accuracy= 0.60547\n",
      "Iter 170, Minibatch Loss= 1.158381, Training Accuracy= 0.58203\n",
      "Iter 180, Minibatch Loss= 1.044892, Training Accuracy= 0.65234\n",
      "Iter 190, Minibatch Loss= 1.044957, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6182\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_25:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.155586, Training Accuracy= 0.16797\n",
      "Iter 10, Minibatch Loss= 2.716730, Training Accuracy= 0.23047\n",
      "Iter 20, Minibatch Loss= 2.206979, Training Accuracy= 0.24609\n",
      "Iter 30, Minibatch Loss= 1.933152, Training Accuracy= 0.33984\n",
      "Iter 40, Minibatch Loss= 1.643037, Training Accuracy= 0.48047\n",
      "Iter 50, Minibatch Loss= 1.442004, Training Accuracy= 0.53516\n",
      "Iter 60, Minibatch Loss= 1.409691, Training Accuracy= 0.49219\n",
      "Iter 70, Minibatch Loss= 1.232393, Training Accuracy= 0.55078\n",
      "Iter 80, Minibatch Loss= 1.097281, Training Accuracy= 0.61328\n",
      "Iter 90, Minibatch Loss= 1.344907, Training Accuracy= 0.54297\n",
      "Iter 100, Minibatch Loss= 1.183135, Training Accuracy= 0.58594\n",
      "Iter 110, Minibatch Loss= 1.073906, Training Accuracy= 0.60156\n",
      "Iter 120, Minibatch Loss= 1.174006, Training Accuracy= 0.60156\n",
      "Iter 130, Minibatch Loss= 1.239277, Training Accuracy= 0.57031\n",
      "Iter 140, Minibatch Loss= 1.156229, Training Accuracy= 0.60547\n",
      "Iter 150, Minibatch Loss= 1.130903, Training Accuracy= 0.61328\n",
      "Iter 160, Minibatch Loss= 1.305107, Training Accuracy= 0.56250\n",
      "Iter 170, Minibatch Loss= 1.218976, Training Accuracy= 0.56250\n",
      "Iter 180, Minibatch Loss= 1.331943, Training Accuracy= 0.53125\n",
      "Iter 190, Minibatch Loss= 1.007307, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.608\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_27:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.648086, Training Accuracy= 0.12500\n",
      "Iter 10, Minibatch Loss= 3.058161, Training Accuracy= 0.20703\n",
      "Iter 20, Minibatch Loss= 2.262810, Training Accuracy= 0.28906\n",
      "Iter 30, Minibatch Loss= 1.906449, Training Accuracy= 0.35938\n",
      "Iter 40, Minibatch Loss= 1.732219, Training Accuracy= 0.40234\n",
      "Iter 50, Minibatch Loss= 1.375685, Training Accuracy= 0.51562\n",
      "Iter 60, Minibatch Loss= 1.430748, Training Accuracy= 0.49609\n",
      "Iter 70, Minibatch Loss= 1.377602, Training Accuracy= 0.51562\n",
      "Iter 80, Minibatch Loss= 1.477546, Training Accuracy= 0.54297\n",
      "Iter 90, Minibatch Loss= 1.358245, Training Accuracy= 0.51172\n",
      "Iter 100, Minibatch Loss= 1.189856, Training Accuracy= 0.58984\n",
      "Iter 110, Minibatch Loss= 1.351483, Training Accuracy= 0.53906\n",
      "Iter 120, Minibatch Loss= 1.247040, Training Accuracy= 0.58203\n",
      "Iter 130, Minibatch Loss= 1.172050, Training Accuracy= 0.61719\n",
      "Iter 140, Minibatch Loss= 1.131495, Training Accuracy= 0.60547\n",
      "Iter 150, Minibatch Loss= 1.197808, Training Accuracy= 0.54688\n",
      "Iter 160, Minibatch Loss= 1.048452, Training Accuracy= 0.62500\n",
      "Iter 170, Minibatch Loss= 1.088977, Training Accuracy= 0.62500\n",
      "Iter 180, Minibatch Loss= 1.135816, Training Accuracy= 0.63281\n",
      "Iter 190, Minibatch Loss= 1.222778, Training Accuracy= 0.57422\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6349\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_29:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.001904, Training Accuracy= 0.11719\n",
      "Iter 10, Minibatch Loss= 2.760800, Training Accuracy= 0.28125\n",
      "Iter 20, Minibatch Loss= 2.108330, Training Accuracy= 0.33203\n",
      "Iter 30, Minibatch Loss= 1.727336, Training Accuracy= 0.37500\n",
      "Iter 40, Minibatch Loss= 1.691715, Training Accuracy= 0.40234\n",
      "Iter 50, Minibatch Loss= 1.519775, Training Accuracy= 0.48438\n",
      "Iter 60, Minibatch Loss= 1.399861, Training Accuracy= 0.48828\n",
      "Iter 70, Minibatch Loss= 1.407083, Training Accuracy= 0.51172\n",
      "Iter 80, Minibatch Loss= 1.294058, Training Accuracy= 0.58594\n",
      "Iter 90, Minibatch Loss= 1.287244, Training Accuracy= 0.54297\n",
      "Iter 100, Minibatch Loss= 1.175987, Training Accuracy= 0.58203\n",
      "Iter 110, Minibatch Loss= 1.159353, Training Accuracy= 0.62109\n",
      "Iter 120, Minibatch Loss= 1.124035, Training Accuracy= 0.62109\n",
      "Iter 130, Minibatch Loss= 0.991785, Training Accuracy= 0.65625\n",
      "Iter 140, Minibatch Loss= 1.018858, Training Accuracy= 0.65625\n",
      "Iter 150, Minibatch Loss= 1.068855, Training Accuracy= 0.62109\n",
      "Iter 160, Minibatch Loss= 1.057297, Training Accuracy= 0.62500\n",
      "Iter 170, Minibatch Loss= 1.096092, Training Accuracy= 0.60938\n",
      "Iter 180, Minibatch Loss= 1.053579, Training Accuracy= 0.64062\n",
      "Iter 190, Minibatch Loss= 1.029480, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6323\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_31:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.480519, Training Accuracy= 0.14062\n",
      "Iter 10, Minibatch Loss= 3.546609, Training Accuracy= 0.10938\n",
      "Iter 20, Minibatch Loss= 2.727908, Training Accuracy= 0.23828\n",
      "Iter 30, Minibatch Loss= 1.939733, Training Accuracy= 0.36328\n",
      "Iter 40, Minibatch Loss= 1.616066, Training Accuracy= 0.48047\n",
      "Iter 50, Minibatch Loss= 1.679877, Training Accuracy= 0.39062\n",
      "Iter 60, Minibatch Loss= 1.538009, Training Accuracy= 0.50781\n",
      "Iter 70, Minibatch Loss= 1.328851, Training Accuracy= 0.53906\n",
      "Iter 80, Minibatch Loss= 1.368553, Training Accuracy= 0.53906\n",
      "Iter 90, Minibatch Loss= 1.269396, Training Accuracy= 0.55469\n",
      "Iter 100, Minibatch Loss= 1.255366, Training Accuracy= 0.57031\n",
      "Iter 110, Minibatch Loss= 1.282213, Training Accuracy= 0.52734\n",
      "Iter 120, Minibatch Loss= 1.142195, Training Accuracy= 0.58203\n",
      "Iter 130, Minibatch Loss= 1.330784, Training Accuracy= 0.54688\n",
      "Iter 140, Minibatch Loss= 1.208201, Training Accuracy= 0.58203\n",
      "Iter 150, Minibatch Loss= 1.063686, Training Accuracy= 0.61719\n",
      "Iter 160, Minibatch Loss= 1.237447, Training Accuracy= 0.57422\n",
      "Iter 170, Minibatch Loss= 1.216915, Training Accuracy= 0.60547\n",
      "Iter 180, Minibatch Loss= 1.087305, Training Accuracy= 0.61719\n",
      "Iter 190, Minibatch Loss= 1.024844, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6361\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_33:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.734090, Training Accuracy= 0.19141\n",
      "Iter 10, Minibatch Loss= 3.152520, Training Accuracy= 0.23828\n",
      "Iter 20, Minibatch Loss= 2.403766, Training Accuracy= 0.27734\n",
      "Iter 30, Minibatch Loss= 1.795094, Training Accuracy= 0.42969\n",
      "Iter 40, Minibatch Loss= 1.679718, Training Accuracy= 0.43359\n",
      "Iter 50, Minibatch Loss= 1.540867, Training Accuracy= 0.44141\n",
      "Iter 60, Minibatch Loss= 1.387329, Training Accuracy= 0.51953\n",
      "Iter 70, Minibatch Loss= 1.219553, Training Accuracy= 0.56641\n",
      "Iter 80, Minibatch Loss= 1.224863, Training Accuracy= 0.54297\n",
      "Iter 90, Minibatch Loss= 1.040126, Training Accuracy= 0.61328\n",
      "Iter 100, Minibatch Loss= 1.337477, Training Accuracy= 0.54297\n",
      "Iter 110, Minibatch Loss= 1.122882, Training Accuracy= 0.60547\n",
      "Iter 120, Minibatch Loss= 1.063498, Training Accuracy= 0.64844\n",
      "Iter 130, Minibatch Loss= 1.045909, Training Accuracy= 0.67969\n",
      "Iter 140, Minibatch Loss= 1.113482, Training Accuracy= 0.63672\n",
      "Iter 150, Minibatch Loss= 0.971088, Training Accuracy= 0.69531\n",
      "Iter 160, Minibatch Loss= 0.896002, Training Accuracy= 0.69141\n",
      "Iter 170, Minibatch Loss= 1.061606, Training Accuracy= 0.64062\n",
      "Iter 180, Minibatch Loss= 0.857956, Training Accuracy= 0.69922\n",
      "Iter 190, Minibatch Loss= 1.070832, Training Accuracy= 0.64453\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6571\n",
      "Hidden Layer 2 Nodes: 256 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_35:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.808804, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 3.880437, Training Accuracy= 0.09766\n",
      "Iter 20, Minibatch Loss= 2.500445, Training Accuracy= 0.30078\n",
      "Iter 30, Minibatch Loss= 1.977215, Training Accuracy= 0.37891\n",
      "Iter 40, Minibatch Loss= 1.602681, Training Accuracy= 0.43750\n",
      "Iter 50, Minibatch Loss= 1.446638, Training Accuracy= 0.48047\n",
      "Iter 60, Minibatch Loss= 1.290209, Training Accuracy= 0.53125\n",
      "Iter 70, Minibatch Loss= 1.347144, Training Accuracy= 0.54297\n",
      "Iter 80, Minibatch Loss= 1.448984, Training Accuracy= 0.50781\n",
      "Iter 90, Minibatch Loss= 1.237756, Training Accuracy= 0.59375\n",
      "Iter 100, Minibatch Loss= 1.166291, Training Accuracy= 0.61719\n",
      "Iter 110, Minibatch Loss= 1.189319, Training Accuracy= 0.60938\n",
      "Iter 120, Minibatch Loss= 1.219919, Training Accuracy= 0.60156\n",
      "Iter 130, Minibatch Loss= 1.088251, Training Accuracy= 0.60938\n",
      "Iter 140, Minibatch Loss= 1.156486, Training Accuracy= 0.61328\n",
      "Iter 150, Minibatch Loss= 1.129104, Training Accuracy= 0.60938\n",
      "Iter 160, Minibatch Loss= 1.157497, Training Accuracy= 0.62109\n",
      "Iter 170, Minibatch Loss= 1.146002, Training Accuracy= 0.58984\n",
      "Iter 180, Minibatch Loss= 0.991201, Training Accuracy= 0.63281\n",
      "Iter 190, Minibatch Loss= 1.056865, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6162\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_37:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.541084, Training Accuracy= 0.10938\n",
      "Iter 10, Minibatch Loss= 3.102588, Training Accuracy= 0.16406\n",
      "Iter 20, Minibatch Loss= 2.179293, Training Accuracy= 0.32031\n",
      "Iter 30, Minibatch Loss= 1.932542, Training Accuracy= 0.39453\n",
      "Iter 40, Minibatch Loss= 1.671096, Training Accuracy= 0.44141\n",
      "Iter 50, Minibatch Loss= 1.517838, Training Accuracy= 0.47656\n",
      "Iter 60, Minibatch Loss= 1.410459, Training Accuracy= 0.51172\n",
      "Iter 70, Minibatch Loss= 1.208042, Training Accuracy= 0.58203\n",
      "Iter 80, Minibatch Loss= 1.319405, Training Accuracy= 0.52734\n",
      "Iter 90, Minibatch Loss= 1.193958, Training Accuracy= 0.56641\n",
      "Iter 100, Minibatch Loss= 1.154785, Training Accuracy= 0.60547\n",
      "Iter 110, Minibatch Loss= 1.169060, Training Accuracy= 0.61719\n",
      "Iter 120, Minibatch Loss= 0.903429, Training Accuracy= 0.69531\n",
      "Iter 130, Minibatch Loss= 1.154210, Training Accuracy= 0.58984\n",
      "Iter 140, Minibatch Loss= 1.155291, Training Accuracy= 0.58984\n",
      "Iter 150, Minibatch Loss= 1.174243, Training Accuracy= 0.60938\n",
      "Iter 160, Minibatch Loss= 1.176057, Training Accuracy= 0.58203\n",
      "Iter 170, Minibatch Loss= 1.054917, Training Accuracy= 0.63281\n",
      "Iter 180, Minibatch Loss= 1.082914, Training Accuracy= 0.67578\n",
      "Iter 190, Minibatch Loss= 1.260712, Training Accuracy= 0.55859\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6243\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_39:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.827364, Training Accuracy= 0.11328\n",
      "Iter 10, Minibatch Loss= 2.676850, Training Accuracy= 0.12500\n",
      "Iter 20, Minibatch Loss= 2.245426, Training Accuracy= 0.25391\n",
      "Iter 30, Minibatch Loss= 1.909456, Training Accuracy= 0.35547\n",
      "Iter 40, Minibatch Loss= 1.565044, Training Accuracy= 0.51562\n",
      "Iter 50, Minibatch Loss= 1.627119, Training Accuracy= 0.46484\n",
      "Iter 60, Minibatch Loss= 1.399856, Training Accuracy= 0.50000\n",
      "Iter 70, Minibatch Loss= 1.332732, Training Accuracy= 0.56250\n",
      "Iter 80, Minibatch Loss= 1.476991, Training Accuracy= 0.50781\n",
      "Iter 90, Minibatch Loss= 1.377119, Training Accuracy= 0.52734\n",
      "Iter 100, Minibatch Loss= 1.279229, Training Accuracy= 0.58594\n",
      "Iter 110, Minibatch Loss= 1.238408, Training Accuracy= 0.59766\n",
      "Iter 120, Minibatch Loss= 1.262455, Training Accuracy= 0.62500\n",
      "Iter 130, Minibatch Loss= 1.094620, Training Accuracy= 0.63281\n",
      "Iter 140, Minibatch Loss= 0.993681, Training Accuracy= 0.66406\n",
      "Iter 150, Minibatch Loss= 0.981497, Training Accuracy= 0.64062\n",
      "Iter 160, Minibatch Loss= 1.094177, Training Accuracy= 0.63672\n",
      "Iter 170, Minibatch Loss= 1.020590, Training Accuracy= 0.63281\n",
      "Iter 180, Minibatch Loss= 0.954436, Training Accuracy= 0.66016\n",
      "Iter 190, Minibatch Loss= 1.204446, Training Accuracy= 0.63281\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6385\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_41:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.327886, Training Accuracy= 0.07812\n",
      "Iter 10, Minibatch Loss= 3.238071, Training Accuracy= 0.16406\n",
      "Iter 20, Minibatch Loss= 2.106368, Training Accuracy= 0.32812\n",
      "Iter 30, Minibatch Loss= 1.888777, Training Accuracy= 0.40625\n",
      "Iter 40, Minibatch Loss= 1.714401, Training Accuracy= 0.39062\n",
      "Iter 50, Minibatch Loss= 1.405735, Training Accuracy= 0.52344\n",
      "Iter 60, Minibatch Loss= 1.352882, Training Accuracy= 0.51562\n",
      "Iter 70, Minibatch Loss= 1.331667, Training Accuracy= 0.58984\n",
      "Iter 80, Minibatch Loss= 1.328929, Training Accuracy= 0.56641\n",
      "Iter 90, Minibatch Loss= 1.233260, Training Accuracy= 0.61719\n",
      "Iter 100, Minibatch Loss= 1.100144, Training Accuracy= 0.61719\n",
      "Iter 110, Minibatch Loss= 1.138051, Training Accuracy= 0.60156\n",
      "Iter 120, Minibatch Loss= 1.024542, Training Accuracy= 0.65234\n",
      "Iter 130, Minibatch Loss= 1.102798, Training Accuracy= 0.60156\n",
      "Iter 140, Minibatch Loss= 1.110266, Training Accuracy= 0.58594\n",
      "Iter 150, Minibatch Loss= 1.202618, Training Accuracy= 0.58594\n",
      "Iter 160, Minibatch Loss= 0.961167, Training Accuracy= 0.66406\n",
      "Iter 170, Minibatch Loss= 1.133115, Training Accuracy= 0.58594\n",
      "Iter 180, Minibatch Loss= 1.081180, Training Accuracy= 0.59766\n",
      "Iter 190, Minibatch Loss= 0.969205, Training Accuracy= 0.66406\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6446\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_43:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.132419, Training Accuracy= 0.16016\n",
      "Iter 10, Minibatch Loss= 2.613376, Training Accuracy= 0.25000\n",
      "Iter 20, Minibatch Loss= 2.317620, Training Accuracy= 0.30078\n",
      "Iter 30, Minibatch Loss= 1.875007, Training Accuracy= 0.36719\n",
      "Iter 40, Minibatch Loss= 1.595662, Training Accuracy= 0.44141\n",
      "Iter 50, Minibatch Loss= 1.568740, Training Accuracy= 0.44141\n",
      "Iter 60, Minibatch Loss= 1.404918, Training Accuracy= 0.50000\n",
      "Iter 70, Minibatch Loss= 1.399246, Training Accuracy= 0.51953\n",
      "Iter 80, Minibatch Loss= 1.220064, Training Accuracy= 0.53906\n",
      "Iter 90, Minibatch Loss= 1.308320, Training Accuracy= 0.55469\n",
      "Iter 100, Minibatch Loss= 1.276048, Training Accuracy= 0.58984\n",
      "Iter 110, Minibatch Loss= 1.091668, Training Accuracy= 0.62891\n",
      "Iter 120, Minibatch Loss= 1.116902, Training Accuracy= 0.58594\n",
      "Iter 130, Minibatch Loss= 1.037003, Training Accuracy= 0.63672\n",
      "Iter 140, Minibatch Loss= 1.153876, Training Accuracy= 0.61719\n",
      "Iter 150, Minibatch Loss= 1.088916, Training Accuracy= 0.64453\n",
      "Iter 160, Minibatch Loss= 0.998097, Training Accuracy= 0.65625\n",
      "Iter 170, Minibatch Loss= 1.102492, Training Accuracy= 0.62109\n",
      "Iter 180, Minibatch Loss= 1.047243, Training Accuracy= 0.61328\n",
      "Iter 190, Minibatch Loss= 0.965801, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6462\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_45:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 8.050255, Training Accuracy= 0.12891\n",
      "Iter 10, Minibatch Loss= 4.241231, Training Accuracy= 0.10156\n",
      "Iter 20, Minibatch Loss= 2.507619, Training Accuracy= 0.29297\n",
      "Iter 30, Minibatch Loss= 1.988426, Training Accuracy= 0.41797\n",
      "Iter 40, Minibatch Loss= 1.583672, Training Accuracy= 0.49219\n",
      "Iter 50, Minibatch Loss= 1.577470, Training Accuracy= 0.48047\n",
      "Iter 60, Minibatch Loss= 1.305987, Training Accuracy= 0.53906\n",
      "Iter 70, Minibatch Loss= 1.410116, Training Accuracy= 0.51172\n",
      "Iter 80, Minibatch Loss= 1.180527, Training Accuracy= 0.58984\n",
      "Iter 90, Minibatch Loss= 1.230692, Training Accuracy= 0.56641\n",
      "Iter 100, Minibatch Loss= 1.274104, Training Accuracy= 0.55859\n",
      "Iter 110, Minibatch Loss= 1.249353, Training Accuracy= 0.55078\n",
      "Iter 120, Minibatch Loss= 1.106668, Training Accuracy= 0.63281\n",
      "Iter 130, Minibatch Loss= 1.087041, Training Accuracy= 0.64453\n",
      "Iter 140, Minibatch Loss= 1.166678, Training Accuracy= 0.58594\n",
      "Iter 150, Minibatch Loss= 1.103426, Training Accuracy= 0.61719\n",
      "Iter 160, Minibatch Loss= 1.058352, Training Accuracy= 0.60547\n",
      "Iter 170, Minibatch Loss= 1.042670, Training Accuracy= 0.62500\n",
      "Iter 180, Minibatch Loss= 1.089688, Training Accuracy= 0.64844\n",
      "Iter 190, Minibatch Loss= 1.046803, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6483\n",
      "Hidden Layer 2 Nodes: 320 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_47:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.979310, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 3.142110, Training Accuracy= 0.16797\n",
      "Iter 20, Minibatch Loss= 2.207728, Training Accuracy= 0.27344\n",
      "Iter 30, Minibatch Loss= 1.745390, Training Accuracy= 0.40625\n",
      "Iter 40, Minibatch Loss= 1.629691, Training Accuracy= 0.43359\n",
      "Iter 50, Minibatch Loss= 1.523691, Training Accuracy= 0.45703\n",
      "Iter 60, Minibatch Loss= 1.289806, Training Accuracy= 0.52734\n",
      "Iter 70, Minibatch Loss= 1.307271, Training Accuracy= 0.55469\n",
      "Iter 80, Minibatch Loss= 1.284596, Training Accuracy= 0.59766\n",
      "Iter 90, Minibatch Loss= 1.233572, Training Accuracy= 0.58203\n",
      "Iter 100, Minibatch Loss= 1.153818, Training Accuracy= 0.61719\n",
      "Iter 110, Minibatch Loss= 1.269106, Training Accuracy= 0.58984\n",
      "Iter 120, Minibatch Loss= 1.141596, Training Accuracy= 0.60547\n",
      "Iter 130, Minibatch Loss= 1.060382, Training Accuracy= 0.62500\n",
      "Iter 140, Minibatch Loss= 1.107784, Training Accuracy= 0.60547\n",
      "Iter 150, Minibatch Loss= 1.188958, Training Accuracy= 0.61328\n",
      "Iter 160, Minibatch Loss= 1.110459, Training Accuracy= 0.61719\n",
      "Iter 170, Minibatch Loss= 1.149286, Training Accuracy= 0.58203\n",
      "Iter 180, Minibatch Loss= 1.023187, Training Accuracy= 0.62109\n",
      "Iter 190, Minibatch Loss= 0.961536, Training Accuracy= 0.68359\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6263\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_49:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.268281, Training Accuracy= 0.05859\n",
      "Iter 10, Minibatch Loss= 4.054501, Training Accuracy= 0.08594\n",
      "Iter 20, Minibatch Loss= 2.906145, Training Accuracy= 0.30469\n",
      "Iter 30, Minibatch Loss= 2.153399, Training Accuracy= 0.37891\n",
      "Iter 40, Minibatch Loss= 1.729401, Training Accuracy= 0.40234\n",
      "Iter 50, Minibatch Loss= 1.501018, Training Accuracy= 0.51953\n",
      "Iter 60, Minibatch Loss= 1.395502, Training Accuracy= 0.55859\n",
      "Iter 70, Minibatch Loss= 1.300997, Training Accuracy= 0.55859\n",
      "Iter 80, Minibatch Loss= 1.236987, Training Accuracy= 0.56250\n",
      "Iter 90, Minibatch Loss= 1.208511, Training Accuracy= 0.60938\n",
      "Iter 100, Minibatch Loss= 1.233349, Training Accuracy= 0.60547\n",
      "Iter 110, Minibatch Loss= 1.079004, Training Accuracy= 0.62109\n",
      "Iter 120, Minibatch Loss= 1.199265, Training Accuracy= 0.58203\n",
      "Iter 130, Minibatch Loss= 1.088438, Training Accuracy= 0.62109\n",
      "Iter 140, Minibatch Loss= 1.006707, Training Accuracy= 0.66797\n",
      "Iter 150, Minibatch Loss= 1.015264, Training Accuracy= 0.66016\n",
      "Iter 160, Minibatch Loss= 1.026001, Training Accuracy= 0.67578\n",
      "Iter 170, Minibatch Loss= 1.005793, Training Accuracy= 0.66797\n",
      "Iter 180, Minibatch Loss= 1.079280, Training Accuracy= 0.63281\n",
      "Iter 190, Minibatch Loss= 1.043880, Training Accuracy= 0.64453\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6456\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_51:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.542267, Training Accuracy= 0.15625\n",
      "Iter 10, Minibatch Loss= 2.464597, Training Accuracy= 0.24609\n",
      "Iter 20, Minibatch Loss= 1.876598, Training Accuracy= 0.38281\n",
      "Iter 30, Minibatch Loss= 1.587608, Training Accuracy= 0.44141\n",
      "Iter 40, Minibatch Loss= 1.570095, Training Accuracy= 0.49219\n",
      "Iter 50, Minibatch Loss= 1.356691, Training Accuracy= 0.53906\n",
      "Iter 60, Minibatch Loss= 1.211686, Training Accuracy= 0.58984\n",
      "Iter 70, Minibatch Loss= 1.158020, Training Accuracy= 0.61719\n",
      "Iter 80, Minibatch Loss= 1.115510, Training Accuracy= 0.60547\n",
      "Iter 90, Minibatch Loss= 1.177845, Training Accuracy= 0.57812\n",
      "Iter 100, Minibatch Loss= 1.144819, Training Accuracy= 0.61328\n",
      "Iter 110, Minibatch Loss= 1.039609, Training Accuracy= 0.63281\n",
      "Iter 120, Minibatch Loss= 1.104976, Training Accuracy= 0.63281\n",
      "Iter 130, Minibatch Loss= 1.093741, Training Accuracy= 0.64453\n",
      "Iter 140, Minibatch Loss= 1.048065, Training Accuracy= 0.65234\n",
      "Iter 150, Minibatch Loss= 0.869228, Training Accuracy= 0.70312\n",
      "Iter 160, Minibatch Loss= 0.911736, Training Accuracy= 0.67188\n",
      "Iter 170, Minibatch Loss= 0.943496, Training Accuracy= 0.67578\n",
      "Iter 180, Minibatch Loss= 0.965434, Training Accuracy= 0.66406\n",
      "Iter 190, Minibatch Loss= 1.022995, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6605\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_53:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.525269, Training Accuracy= 0.04297\n",
      "Iter 10, Minibatch Loss= 2.505429, Training Accuracy= 0.23828\n",
      "Iter 20, Minibatch Loss= 2.145066, Training Accuracy= 0.31641\n",
      "Iter 30, Minibatch Loss= 1.816910, Training Accuracy= 0.42188\n",
      "Iter 40, Minibatch Loss= 1.565548, Training Accuracy= 0.45703\n",
      "Iter 50, Minibatch Loss= 1.464529, Training Accuracy= 0.53125\n",
      "Iter 60, Minibatch Loss= 1.230755, Training Accuracy= 0.59375\n",
      "Iter 70, Minibatch Loss= 1.217046, Training Accuracy= 0.57812\n",
      "Iter 80, Minibatch Loss= 1.305165, Training Accuracy= 0.54688\n",
      "Iter 90, Minibatch Loss= 1.209893, Training Accuracy= 0.57422\n",
      "Iter 100, Minibatch Loss= 1.136972, Training Accuracy= 0.61328\n",
      "Iter 110, Minibatch Loss= 1.050123, Training Accuracy= 0.64453\n",
      "Iter 120, Minibatch Loss= 1.161974, Training Accuracy= 0.64062\n",
      "Iter 130, Minibatch Loss= 1.081985, Training Accuracy= 0.64062\n",
      "Iter 140, Minibatch Loss= 1.042952, Training Accuracy= 0.62891\n",
      "Iter 150, Minibatch Loss= 0.920035, Training Accuracy= 0.69922\n",
      "Iter 160, Minibatch Loss= 1.024169, Training Accuracy= 0.66016\n",
      "Iter 170, Minibatch Loss= 0.943859, Training Accuracy= 0.69531\n",
      "Iter 180, Minibatch Loss= 0.875283, Training Accuracy= 0.69141\n",
      "Iter 190, Minibatch Loss= 0.988207, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6714\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_55:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.369061, Training Accuracy= 0.05078\n",
      "Iter 10, Minibatch Loss= 2.714227, Training Accuracy= 0.25000\n",
      "Iter 20, Minibatch Loss= 2.130418, Training Accuracy= 0.31641\n",
      "Iter 30, Minibatch Loss= 1.763316, Training Accuracy= 0.37891\n",
      "Iter 40, Minibatch Loss= 1.493222, Training Accuracy= 0.48047\n",
      "Iter 50, Minibatch Loss= 1.363731, Training Accuracy= 0.52344\n",
      "Iter 60, Minibatch Loss= 1.394286, Training Accuracy= 0.53125\n",
      "Iter 70, Minibatch Loss= 1.216775, Training Accuracy= 0.57422\n",
      "Iter 80, Minibatch Loss= 1.195225, Training Accuracy= 0.62109\n",
      "Iter 90, Minibatch Loss= 1.318959, Training Accuracy= 0.52734\n",
      "Iter 100, Minibatch Loss= 1.364691, Training Accuracy= 0.51172\n",
      "Iter 110, Minibatch Loss= 1.182665, Training Accuracy= 0.60156\n",
      "Iter 120, Minibatch Loss= 1.226405, Training Accuracy= 0.61328\n",
      "Iter 130, Minibatch Loss= 1.127800, Training Accuracy= 0.61719\n",
      "Iter 140, Minibatch Loss= 1.054149, Training Accuracy= 0.63672\n",
      "Iter 150, Minibatch Loss= 1.137355, Training Accuracy= 0.57812\n",
      "Iter 160, Minibatch Loss= 1.268324, Training Accuracy= 0.58594\n",
      "Iter 170, Minibatch Loss= 1.175530, Training Accuracy= 0.60547\n",
      "Iter 180, Minibatch Loss= 1.009484, Training Accuracy= 0.64453\n",
      "Iter 190, Minibatch Loss= 1.115960, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6381\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_57:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 10.462490, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 4.585501, Training Accuracy= 0.05859\n",
      "Iter 20, Minibatch Loss= 2.952175, Training Accuracy= 0.17578\n",
      "Iter 30, Minibatch Loss= 2.172163, Training Accuracy= 0.32422\n",
      "Iter 40, Minibatch Loss= 1.747716, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.608816, Training Accuracy= 0.47656\n",
      "Iter 60, Minibatch Loss= 1.507996, Training Accuracy= 0.50000\n",
      "Iter 70, Minibatch Loss= 1.531392, Training Accuracy= 0.46875\n",
      "Iter 80, Minibatch Loss= 1.365467, Training Accuracy= 0.55078\n",
      "Iter 90, Minibatch Loss= 1.335411, Training Accuracy= 0.54688\n",
      "Iter 100, Minibatch Loss= 1.175372, Training Accuracy= 0.57031\n",
      "Iter 110, Minibatch Loss= 1.253972, Training Accuracy= 0.58203\n",
      "Iter 120, Minibatch Loss= 1.286997, Training Accuracy= 0.53125\n",
      "Iter 130, Minibatch Loss= 1.086561, Training Accuracy= 0.62891\n",
      "Iter 140, Minibatch Loss= 1.150653, Training Accuracy= 0.64062\n",
      "Iter 150, Minibatch Loss= 1.120798, Training Accuracy= 0.62109\n",
      "Iter 160, Minibatch Loss= 1.029097, Training Accuracy= 0.62891\n",
      "Iter 170, Minibatch Loss= 0.973799, Training Accuracy= 0.64453\n",
      "Iter 180, Minibatch Loss= 1.025620, Training Accuracy= 0.67969\n",
      "Iter 190, Minibatch Loss= 0.985732, Training Accuracy= 0.64844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6477\n",
      "Hidden Layer 2 Nodes: 384 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_59:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.185655, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 3.175989, Training Accuracy= 0.10938\n",
      "Iter 20, Minibatch Loss= 2.387141, Training Accuracy= 0.25000\n",
      "Iter 30, Minibatch Loss= 1.851747, Training Accuracy= 0.32422\n",
      "Iter 40, Minibatch Loss= 1.565529, Training Accuracy= 0.46875\n",
      "Iter 50, Minibatch Loss= 1.510170, Training Accuracy= 0.49609\n",
      "Iter 60, Minibatch Loss= 1.519286, Training Accuracy= 0.48438\n",
      "Iter 70, Minibatch Loss= 1.276883, Training Accuracy= 0.57422\n",
      "Iter 80, Minibatch Loss= 1.336430, Training Accuracy= 0.54688\n",
      "Iter 90, Minibatch Loss= 1.326883, Training Accuracy= 0.54297\n",
      "Iter 100, Minibatch Loss= 1.291417, Training Accuracy= 0.57031\n",
      "Iter 110, Minibatch Loss= 1.349339, Training Accuracy= 0.53516\n",
      "Iter 120, Minibatch Loss= 1.215542, Training Accuracy= 0.57812\n",
      "Iter 130, Minibatch Loss= 1.281939, Training Accuracy= 0.56641\n",
      "Iter 140, Minibatch Loss= 1.128001, Training Accuracy= 0.62500\n",
      "Iter 150, Minibatch Loss= 1.157109, Training Accuracy= 0.60938\n",
      "Iter 160, Minibatch Loss= 1.175127, Training Accuracy= 0.60547\n",
      "Iter 170, Minibatch Loss= 1.179836, Training Accuracy= 0.57422\n",
      "Iter 180, Minibatch Loss= 1.086589, Training Accuracy= 0.63672\n",
      "Iter 190, Minibatch Loss= 1.107718, Training Accuracy= 0.60156\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.624\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 128 Accuracy: Tensor(\"Mean_61:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.133690, Training Accuracy= 0.11719\n",
      "Iter 10, Minibatch Loss= 2.751379, Training Accuracy= 0.12109\n",
      "Iter 20, Minibatch Loss= 2.403623, Training Accuracy= 0.21484\n",
      "Iter 30, Minibatch Loss= 1.905303, Training Accuracy= 0.38672\n",
      "Iter 40, Minibatch Loss= 1.630271, Training Accuracy= 0.45312\n",
      "Iter 50, Minibatch Loss= 1.409272, Training Accuracy= 0.52344\n",
      "Iter 60, Minibatch Loss= 1.281547, Training Accuracy= 0.55469\n",
      "Iter 70, Minibatch Loss= 1.381903, Training Accuracy= 0.55859\n",
      "Iter 80, Minibatch Loss= 1.006989, Training Accuracy= 0.65625\n",
      "Iter 90, Minibatch Loss= 1.100168, Training Accuracy= 0.60938\n",
      "Iter 100, Minibatch Loss= 1.043969, Training Accuracy= 0.62500\n",
      "Iter 110, Minibatch Loss= 1.049278, Training Accuracy= 0.67188\n",
      "Iter 120, Minibatch Loss= 0.965303, Training Accuracy= 0.67578\n",
      "Iter 130, Minibatch Loss= 1.044752, Training Accuracy= 0.67578\n",
      "Iter 140, Minibatch Loss= 1.129717, Training Accuracy= 0.60156\n",
      "Iter 150, Minibatch Loss= 0.892317, Training Accuracy= 0.67578\n",
      "Iter 160, Minibatch Loss= 0.942527, Training Accuracy= 0.68359\n",
      "Iter 170, Minibatch Loss= 1.088020, Training Accuracy= 0.64062\n",
      "Iter 180, Minibatch Loss= 0.975033, Training Accuracy= 0.65234\n",
      "Iter 190, Minibatch Loss= 0.948914, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6665\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 192 Accuracy: Tensor(\"Mean_63:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 3.884781, Training Accuracy= 0.07031\n",
      "Iter 10, Minibatch Loss= 2.464964, Training Accuracy= 0.20312\n",
      "Iter 20, Minibatch Loss= 1.790482, Training Accuracy= 0.41406\n",
      "Iter 30, Minibatch Loss= 1.617106, Training Accuracy= 0.44531\n",
      "Iter 40, Minibatch Loss= 1.335025, Training Accuracy= 0.53906\n",
      "Iter 50, Minibatch Loss= 1.371734, Training Accuracy= 0.52344\n",
      "Iter 60, Minibatch Loss= 1.281495, Training Accuracy= 0.55078\n",
      "Iter 70, Minibatch Loss= 1.174529, Training Accuracy= 0.60156\n",
      "Iter 80, Minibatch Loss= 1.119766, Training Accuracy= 0.61719\n",
      "Iter 90, Minibatch Loss= 1.085524, Training Accuracy= 0.61328\n",
      "Iter 100, Minibatch Loss= 0.940917, Training Accuracy= 0.66406\n",
      "Iter 110, Minibatch Loss= 1.334712, Training Accuracy= 0.58984\n",
      "Iter 120, Minibatch Loss= 1.098062, Training Accuracy= 0.66406\n",
      "Iter 130, Minibatch Loss= 1.159284, Training Accuracy= 0.58203\n",
      "Iter 140, Minibatch Loss= 1.008142, Training Accuracy= 0.66016\n",
      "Iter 150, Minibatch Loss= 0.943755, Training Accuracy= 0.68359\n",
      "Iter 160, Minibatch Loss= 1.057861, Training Accuracy= 0.63672\n",
      "Iter 170, Minibatch Loss= 0.969803, Training Accuracy= 0.66406\n",
      "Iter 180, Minibatch Loss= 1.141276, Training Accuracy= 0.61719\n",
      "Iter 190, Minibatch Loss= 1.125177, Training Accuracy= 0.61328\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6466\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 256 Accuracy: Tensor(\"Mean_65:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.706871, Training Accuracy= 0.08203\n",
      "Iter 10, Minibatch Loss= 2.703213, Training Accuracy= 0.12109\n",
      "Iter 20, Minibatch Loss= 2.165926, Training Accuracy= 0.30469\n",
      "Iter 30, Minibatch Loss= 1.618933, Training Accuracy= 0.46875\n",
      "Iter 40, Minibatch Loss= 1.640229, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.391959, Training Accuracy= 0.53125\n",
      "Iter 60, Minibatch Loss= 1.285884, Training Accuracy= 0.52344\n",
      "Iter 70, Minibatch Loss= 1.332097, Training Accuracy= 0.53906\n",
      "Iter 80, Minibatch Loss= 1.203789, Training Accuracy= 0.57812\n",
      "Iter 90, Minibatch Loss= 1.282928, Training Accuracy= 0.57031\n",
      "Iter 100, Minibatch Loss= 1.130975, Training Accuracy= 0.62891\n",
      "Iter 110, Minibatch Loss= 1.202700, Training Accuracy= 0.59766\n",
      "Iter 120, Minibatch Loss= 1.150510, Training Accuracy= 0.64453\n",
      "Iter 130, Minibatch Loss= 1.279822, Training Accuracy= 0.56641\n",
      "Iter 140, Minibatch Loss= 1.040404, Training Accuracy= 0.64453\n",
      "Iter 150, Minibatch Loss= 1.207859, Training Accuracy= 0.58984\n",
      "Iter 160, Minibatch Loss= 1.025435, Training Accuracy= 0.65625\n",
      "Iter 170, Minibatch Loss= 1.009226, Training Accuracy= 0.63672\n",
      "Iter 180, Minibatch Loss= 1.069464, Training Accuracy= 0.63672\n",
      "Iter 190, Minibatch Loss= 0.934405, Training Accuracy= 0.66406\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6663\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_67:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치를 통한 두 번째와 세 번째 은닉층의 노드 수 탐색\n",
    "for n_hidden2 in range(128, 449, 64): # 128~448까지 64씩 증가\n",
    "    for n_hidden3 in range(128, 449, 64):\n",
    "        # 학습 관련 매개변수 및 모델 구조 정의\n",
    "        n_input = 784\n",
    "        n_hidden1 = 400\n",
    "        n_hidden4 = 50\n",
    "        display_step = 1\n",
    "        n_epoch = 200\n",
    "        batch_size = 256\n",
    "        lr_rbm = tf.constant(0.001, tf.float32)\n",
    "        lr_class = tf.constant(0.01, tf.float32)\n",
    "        n_class = 10\n",
    "        n_iter = 200\n",
    "\n",
    "        # 입력 및 출력 정의\n",
    "        x = tf.placeholder(tf.float32, [None, n_input], name=\"x\")\n",
    "        y = tf.placeholder(tf.float32, [None, 10], name=\"y\")\n",
    "\n",
    "        # 첫 번째 은닉층 가중치 및 편향 정의\n",
    "        W1 = tf.Variable(tf.random_normal([n_input, n_hidden1], 0.01), name=\"W1\")\n",
    "        b1_h = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b1_h\"))\n",
    "        b1_i = tf.Variable(tf.zeros([1, n_input], tf.float32, name=\"b1_i\"))\n",
    "\n",
    "        # 두 번째 은닉층 가중치 및 편향 정의\n",
    "        W2 = tf.Variable(tf.random_normal([n_hidden1, n_hidden2], 0.01), name=\"W2\")\n",
    "        b2_h = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b2_h\"))\n",
    "        b2_i = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b2_i\"))\n",
    "\n",
    "        # 세 번째 은닉층 가중치 및 편향 정의\n",
    "        W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden3], 0.01), name=\"W3\")\n",
    "        b3_h = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b3_h\"))\n",
    "        b3_i = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b3_i\"))\n",
    "\n",
    "        # 네 번째 은닉층 가중치 및 편향 정의\n",
    "        W4 = tf.Variable(tf.random_normal([n_hidden3, n_hidden4], 0.01), name=\"W4\")\n",
    "        b4_h = tf.Variable(tf.zeros([1, n_hidden4], tf.float32, name=\"b4_h\"))\n",
    "        b4_i = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b4_i\"))\n",
    "\n",
    "        # 라벨층 가중치 및 편향 정의\n",
    "        W_c = tf.Variable(tf.random_normal([n_hidden4, n_class], 0.01), name=\"W_c\")\n",
    "        b_c = tf.Variable(tf.zeros([1, n_class], tf.float32, name=\"b_c\"))\n",
    "\n",
    "        # 확률을 이산 상태, 즉 0과 1로 변환함 \n",
    "        def binary(prob):\n",
    "            return tf.floor(prob + tf.random_uniform(tf.shape(prob), 0, 1))\n",
    "        \n",
    "        # Gibbs 표본추출 단계\n",
    "        def cd_step(x_k,W,b_h,b_i):\n",
    "            h_k = binary(tf.sigmoid(tf.matmul(x_k, W) + b_h)) \n",
    "            x_k = binary(tf.sigmoid(tf.matmul(h_k, tf.transpose(W)) + b_i))\n",
    "            return x_k\n",
    "        \n",
    "        # 표본추출 단계 실행     \n",
    "        def cd_gibbs(k,x_k,W,b_h,b_i):\n",
    "            for i in range(k):\n",
    "                x_out = cd_step(x_k,W,b_h,b_i) \n",
    "            # k 반복 후에 깁스 표본을 반환함\n",
    "            return x_out\n",
    "        \n",
    "        # 4개의 은닉층을 갖는 DBN에 대한 CD-2 알고리즘\n",
    "        # 1. 현재 입력값을 기반으로 깁스 표본추출을 통해 새로운 입력값 x_s를 구함\n",
    "        # 2. 새로운 x_s를 기반으로 새로운 은닉노드 값 h_s를 구함    \n",
    "        x_s = cd_gibbs(2,x,W1,b1_h,b1_i) \n",
    "        act_h1_s = binary(tf.sigmoid(tf.matmul(x_s, W1) + b1_h)) \n",
    "        h1_s = cd_gibbs(2,act_h1_s,W2,b2_h,b2_i) \n",
    "        act_h2_s = binary(tf.sigmoid(tf.matmul(h1_s, W2) + b2_h)) \n",
    "        h2_s = cd_gibbs(2, act_h2_s, W3, b3_h, b3_i)  \n",
    "        act_h3_s = binary(tf.sigmoid(tf.matmul(h2_s, W3) + b3_h))\n",
    "        h3_s = cd_gibbs(2, act_h3_s, W4, b4_h, b4_i)  \n",
    "        act_h4_s = binary(tf.sigmoid(tf.matmul(h3_s, W4) + b4_h))\n",
    "        \n",
    "        # 입력값이 주어질 때 은닉노드 값 h를 구함\n",
    "        act_h1 = tf.sigmoid(tf.matmul(x, W1) + b1_h) \n",
    "        act_h2 = tf.sigmoid(tf.matmul(act_h1_s, W2) + b2_h)\n",
    "        act_h3 = tf.sigmoid(tf.matmul(act_h2_s, W3) + b3_h) \n",
    "        act_h4 = tf.sigmoid(tf.matmul(act_h3_s, W4) + b4_h) \n",
    "        \n",
    "        # 경사 하강법을 이용한 가중치 및 편향 업데이트 \n",
    "        size_batch = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "        # 첫 번째 은닉층\n",
    "        W1_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(x), \\\n",
    "                  act_h1), tf.matmul(tf.transpose(x_s), act_h1_s)))\n",
    "        b1_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(x, x_s), \\\n",
    "                   0, True))\n",
    "        b1_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1, act_h1_s), \\\n",
    "                   0, True))\n",
    "        \n",
    "        # 두 번째 은닉층\n",
    "        W2_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h1_s), \\\n",
    "                  act_h2), tf.matmul(tf.transpose(h1_s), act_h2_s)))\n",
    "        b2_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1_s, h1_s), \\\n",
    "                   0, True))\n",
    "        b2_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2, act_h2_s), \\\n",
    "                0, True))\n",
    "        \n",
    "        # 세 번째 은닉층\n",
    "        W3_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h2_s), \\\n",
    "                  act_h3), tf.matmul(tf.transpose(h2_s), act_h3_s)))  \n",
    "        b3_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2_s, h2_s), \\\n",
    "                   0, True))  \n",
    "        b3_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3, act_h3_s), \\\n",
    "                 0, True))  \n",
    "        \n",
    "        # 네 번째 은닉층\n",
    "        W4_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h3_s), \\\n",
    "                  act_h4), tf.matmul(tf.transpose(h3_s), act_h4_s)))  \n",
    "        b4_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3_s, h3_s), \\\n",
    "                   0, True))  \n",
    "        b4_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h4, act_h4_s), \\\n",
    "                 0, True))  \n",
    "        \n",
    "        updt = [W1.assign_add(W1_add), b1_i.assign_add(b1_i_add), b1_h.assign_add(b1_h_add),\\\n",
    "                W2.assign_add(W2_add), b2_i.assign_add(b2_i_add), b2_h.assign_add(b2_h_add),\\\n",
    "                W3.assign_add(W3_add), b3_i.assign_add(b3_i_add), b3_h.assign_add(b3_h_add),\\\n",
    "                W4.assign_add(W4_add), b4_i.assign_add(b4_i_add), b4_h.assign_add(b4_h_add)] \n",
    "        \n",
    "        #-------------------------------------------------------------\n",
    "        # 소프트맥스 층을 추가한 분류용-DBN 을 위한 연산과정\n",
    "        #------------------------------------------------------------- \n",
    "        \n",
    "        logits = tf.matmul(act_h4,W_c) + b_c\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr_class).minimize(cost)\n",
    "        correct_pred = tf.equal(tf.argmax(logits,1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        #-------------------------------------------------------------                   \n",
    "        # RBM을 쌓아 올려가며 DBN을 학습하는 텐서플로 그래프 실행   \n",
    "        #-------------------------------------------------------------\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize the variables of the Model\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            \n",
    "            n_batch = int(len(x_train)/batch_size)\n",
    "            # Start the training \n",
    "            for epoch in range(n_epoch):\n",
    "                # Loop over all batches\n",
    "                for i in range(n_batch):\n",
    "                    batch_xs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                    # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                    batch_xs = batch_xs.reshape((-1, 784))\n",
    "                    batch_xs = (batch_xs > 0)*1\n",
    "                    # Run the weight update \n",
    "                    _ = sess.run(updt, feed_dict={x:batch_xs})\n",
    "                    \n",
    "                # Display the running step \n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1))\n",
    "                          \n",
    "            print(\"RBM training Completed !\")\n",
    "        #--------------------------------------------------------------\n",
    "        # 소프트맥스 층을 추가한 분류용-DBN 학습 및 예측\n",
    "        #--------------------------------------------------------------\n",
    "            for i in range(n_iter):\n",
    "                indices = np.random.randint(len(x_train), size=batch_size)\n",
    "                batch_x = x_train[indices]\n",
    "                batch_y = y_train[indices]\n",
    "        \n",
    "                # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                batch_x = batch_x.reshape((-1, 784))\n",
    "                # ++ 레이블 데이터를 원-핫 인코딩\n",
    "                batch_y = np.eye(10)[batch_y]\n",
    "            \n",
    "                # 최적화 과정 실행\n",
    "                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "                if i % 10 == 0:\n",
    "                    # MINIST 훈련용 이미지의 배치에 대한 손실과 정확도를 계산\n",
    "                    tr_loss, tr_acc = sess.run([cost, accuracy], \n",
    "                    \t                    feed_dict={x: batch_x, y: batch_y})\n",
    "                    print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.6f}\".format(tr_loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.5f}\".format(tr_acc))\n",
    "                \n",
    "            print(\"Optimization Finished!\")\n",
    "        \n",
    "            # MINIST 검정용 이미지에 대한 정확도 계산 \n",
    "            print(\"Testing Accuracy:\", \\\n",
    "                sess.run(accuracy, feed_dict={x: x_test.reshape((-1, 784)), #타입 수정\n",
    "                                              y: np.eye(10)[y_test]})) #타입 수정\n",
    "        \n",
    "            sess.close()\n",
    "             \n",
    "        print(\"Hidden Layer 2 Nodes:\", n_hidden2, \"Hidden Layer 3 Nodes:\", n_hidden3, \"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e6139d-ac1e-45b1-b43a-03ec9bede18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\유승미\\AppData\\Local\\Temp\\ipykernel_10796\\1797260749.py:123: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.652671, Training Accuracy= 0.08203\n",
      "Iter 10, Minibatch Loss= 3.982661, Training Accuracy= 0.08594\n",
      "Iter 20, Minibatch Loss= 2.766175, Training Accuracy= 0.27734\n",
      "Iter 30, Minibatch Loss= 2.077339, Training Accuracy= 0.36719\n",
      "Iter 40, Minibatch Loss= 1.910303, Training Accuracy= 0.38281\n",
      "Iter 50, Minibatch Loss= 1.745079, Training Accuracy= 0.45703\n",
      "Iter 60, Minibatch Loss= 1.518675, Training Accuracy= 0.48438\n",
      "Iter 70, Minibatch Loss= 1.416616, Training Accuracy= 0.50781\n",
      "Iter 80, Minibatch Loss= 1.420468, Training Accuracy= 0.50781\n",
      "Iter 90, Minibatch Loss= 1.277329, Training Accuracy= 0.58984\n",
      "Iter 100, Minibatch Loss= 1.261844, Training Accuracy= 0.55859\n",
      "Iter 110, Minibatch Loss= 1.231671, Training Accuracy= 0.58594\n",
      "Iter 120, Minibatch Loss= 1.286961, Training Accuracy= 0.55859\n",
      "Iter 130, Minibatch Loss= 1.171107, Training Accuracy= 0.57031\n",
      "Iter 140, Minibatch Loss= 1.127905, Training Accuracy= 0.63672\n",
      "Iter 150, Minibatch Loss= 1.112875, Training Accuracy= 0.59766\n",
      "Iter 160, Minibatch Loss= 1.015789, Training Accuracy= 0.59766\n",
      "Iter 170, Minibatch Loss= 1.076340, Training Accuracy= 0.64453\n",
      "Iter 180, Minibatch Loss= 1.084083, Training Accuracy= 0.65625\n",
      "Iter 190, Minibatch Loss= 1.205736, Training Accuracy= 0.63281\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.647\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 320 Accuracy: Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.812095, Training Accuracy= 0.06250\n",
      "Iter 10, Minibatch Loss= 3.140200, Training Accuracy= 0.11719\n",
      "Iter 20, Minibatch Loss= 2.202434, Training Accuracy= 0.33984\n",
      "Iter 30, Minibatch Loss= 1.842718, Training Accuracy= 0.39844\n",
      "Iter 40, Minibatch Loss= 1.593575, Training Accuracy= 0.44141\n",
      "Iter 50, Minibatch Loss= 1.504277, Training Accuracy= 0.51172\n",
      "Iter 60, Minibatch Loss= 1.362779, Training Accuracy= 0.49219\n",
      "Iter 70, Minibatch Loss= 1.305023, Training Accuracy= 0.54297\n",
      "Iter 80, Minibatch Loss= 1.305897, Training Accuracy= 0.55859\n",
      "Iter 90, Minibatch Loss= 1.063619, Training Accuracy= 0.64844\n",
      "Iter 100, Minibatch Loss= 1.203247, Training Accuracy= 0.60547\n",
      "Iter 110, Minibatch Loss= 1.248921, Training Accuracy= 0.57812\n",
      "Iter 120, Minibatch Loss= 1.011630, Training Accuracy= 0.66406\n",
      "Iter 130, Minibatch Loss= 1.234220, Training Accuracy= 0.55469\n",
      "Iter 140, Minibatch Loss= 1.124380, Training Accuracy= 0.60156\n",
      "Iter 150, Minibatch Loss= 0.953173, Training Accuracy= 0.62500\n",
      "Iter 160, Minibatch Loss= 1.003132, Training Accuracy= 0.65234\n",
      "Iter 170, Minibatch Loss= 1.107702, Training Accuracy= 0.62109\n",
      "Iter 180, Minibatch Loss= 1.021853, Training Accuracy= 0.64844\n",
      "Iter 190, Minibatch Loss= 0.879479, Training Accuracy= 0.67578\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6465\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 384 Accuracy: Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.160054, Training Accuracy= 0.08594\n",
      "Iter 10, Minibatch Loss= 3.400419, Training Accuracy= 0.11328\n",
      "Iter 20, Minibatch Loss= 2.108711, Training Accuracy= 0.25391\n",
      "Iter 30, Minibatch Loss= 1.830807, Training Accuracy= 0.38672\n",
      "Iter 40, Minibatch Loss= 1.577034, Training Accuracy= 0.44922\n",
      "Iter 50, Minibatch Loss= 1.393850, Training Accuracy= 0.51562\n",
      "Iter 60, Minibatch Loss= 1.525760, Training Accuracy= 0.44531\n",
      "Iter 70, Minibatch Loss= 1.327506, Training Accuracy= 0.55469\n",
      "Iter 80, Minibatch Loss= 1.248605, Training Accuracy= 0.55078\n",
      "Iter 90, Minibatch Loss= 1.222527, Training Accuracy= 0.57422\n",
      "Iter 100, Minibatch Loss= 1.234021, Training Accuracy= 0.57812\n",
      "Iter 110, Minibatch Loss= 1.276322, Training Accuracy= 0.56641\n",
      "Iter 120, Minibatch Loss= 1.126906, Training Accuracy= 0.61328\n",
      "Iter 130, Minibatch Loss= 1.107364, Training Accuracy= 0.60938\n",
      "Iter 140, Minibatch Loss= 1.213894, Training Accuracy= 0.58984\n",
      "Iter 150, Minibatch Loss= 1.171234, Training Accuracy= 0.60547\n",
      "Iter 160, Minibatch Loss= 0.903676, Training Accuracy= 0.66797\n",
      "Iter 170, Minibatch Loss= 1.209564, Training Accuracy= 0.59375\n",
      "Iter 180, Minibatch Loss= 1.018790, Training Accuracy= 0.62891\n",
      "Iter 190, Minibatch Loss= 0.842705, Training Accuracy= 0.71484\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6669\n",
      "Hidden Layer 2 Nodes: 448 Hidden Layer 3 Nodes: 448 Accuracy: Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for n_hidden3 in range(320, 449, 64): # n_hidden2 = 448일 때, 320~448까지 64씩 증가\n",
    "        # 학습 관련 매개변수 및 모델 구조 정의\n",
    "        n_input = 784\n",
    "        n_hidden1 = 400\n",
    "        n_hidden2 = 448\n",
    "        n_hidden4 = 50\n",
    "        display_step = 1\n",
    "        n_epoch = 200\n",
    "        batch_size = 256\n",
    "        lr_rbm = tf.constant(0.001, tf.float32)\n",
    "        lr_class = tf.constant(0.01, tf.float32)\n",
    "        n_class = 10\n",
    "        n_iter = 200\n",
    "\n",
    "        # 입력 및 출력 정의\n",
    "        x = tf.placeholder(tf.float32, [None, n_input], name=\"x\")\n",
    "        y = tf.placeholder(tf.float32, [None, 10], name=\"y\")\n",
    "\n",
    "        # 첫 번째 은닉층 가중치 및 편향 정의\n",
    "        W1 = tf.Variable(tf.random_normal([n_input, n_hidden1], 0.01), name=\"W1\")\n",
    "        b1_h = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b1_h\"))\n",
    "        b1_i = tf.Variable(tf.zeros([1, n_input], tf.float32, name=\"b1_i\"))\n",
    "\n",
    "        # 두 번째 은닉층 가중치 및 편향 정의\n",
    "        W2 = tf.Variable(tf.random_normal([n_hidden1, n_hidden2], 0.01), name=\"W2\")\n",
    "        b2_h = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b2_h\"))\n",
    "        b2_i = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b2_i\"))\n",
    "\n",
    "        # 세 번째 은닉층 가중치 및 편향 정의\n",
    "        W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden3], 0.01), name=\"W3\")\n",
    "        b3_h = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b3_h\"))\n",
    "        b3_i = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b3_i\"))\n",
    "\n",
    "        # 네 번째 은닉층 가중치 및 편향 정의\n",
    "        W4 = tf.Variable(tf.random_normal([n_hidden3, n_hidden4], 0.01), name=\"W4\")\n",
    "        b4_h = tf.Variable(tf.zeros([1, n_hidden4], tf.float32, name=\"b4_h\"))\n",
    "        b4_i = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b4_i\"))\n",
    "\n",
    "        # 라벨층 가중치 및 편향 정의\n",
    "        W_c = tf.Variable(tf.random_normal([n_hidden4, n_class], 0.01), name=\"W_c\")\n",
    "        b_c = tf.Variable(tf.zeros([1, n_class], tf.float32, name=\"b_c\"))\n",
    "\n",
    "        # 확률을 이산 상태, 즉 0과 1로 변환함 \n",
    "        def binary(prob):\n",
    "            return tf.floor(prob + tf.random_uniform(tf.shape(prob), 0, 1))\n",
    "        \n",
    "        # Gibbs 표본추출 단계\n",
    "        def cd_step(x_k,W,b_h,b_i):\n",
    "            h_k = binary(tf.sigmoid(tf.matmul(x_k, W) + b_h)) \n",
    "            x_k = binary(tf.sigmoid(tf.matmul(h_k, tf.transpose(W)) + b_i))\n",
    "            return x_k\n",
    "        \n",
    "        # 표본추출 단계 실행     \n",
    "        def cd_gibbs(k,x_k,W,b_h,b_i):\n",
    "            for i in range(k):\n",
    "                x_out = cd_step(x_k,W,b_h,b_i) \n",
    "            # k 반복 후에 깁스 표본을 반환함\n",
    "            return x_out\n",
    "        \n",
    "        # 4개의 은닉층을 갖는 DBN에 대한 CD-2 알고리즘\n",
    "        # 1. 현재 입력값을 기반으로 깁스 표본추출을 통해 새로운 입력값 x_s를 구함\n",
    "        # 2. 새로운 x_s를 기반으로 새로운 은닉노드 값 h_s를 구함    \n",
    "        x_s = cd_gibbs(2,x,W1,b1_h,b1_i) \n",
    "        act_h1_s = binary(tf.sigmoid(tf.matmul(x_s, W1) + b1_h)) \n",
    "        h1_s = cd_gibbs(2,act_h1_s,W2,b2_h,b2_i) \n",
    "        act_h2_s = binary(tf.sigmoid(tf.matmul(h1_s, W2) + b2_h)) \n",
    "        h2_s = cd_gibbs(2, act_h2_s, W3, b3_h, b3_i)  \n",
    "        act_h3_s = binary(tf.sigmoid(tf.matmul(h2_s, W3) + b3_h))\n",
    "        h3_s = cd_gibbs(2, act_h3_s, W4, b4_h, b4_i)  \n",
    "        act_h4_s = binary(tf.sigmoid(tf.matmul(h3_s, W4) + b4_h))\n",
    "        \n",
    "        # 입력값이 주어질 때 은닉노드 값 h를 구함\n",
    "        act_h1 = tf.sigmoid(tf.matmul(x, W1) + b1_h) \n",
    "        act_h2 = tf.sigmoid(tf.matmul(act_h1_s, W2) + b2_h)\n",
    "        act_h3 = tf.sigmoid(tf.matmul(act_h2_s, W3) + b3_h) \n",
    "        act_h4 = tf.sigmoid(tf.matmul(act_h3_s, W4) + b4_h) \n",
    "        \n",
    "        # 경사 하강법을 이용한 가중치 및 편향 업데이트 \n",
    "        size_batch = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "        # 첫 번째 은닉층\n",
    "        W1_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(x), \\\n",
    "                  act_h1), tf.matmul(tf.transpose(x_s), act_h1_s)))\n",
    "        b1_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(x, x_s), \\\n",
    "                   0, True))\n",
    "        b1_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1, act_h1_s), \\\n",
    "                   0, True))\n",
    "        \n",
    "        # 두 번째 은닉층\n",
    "        W2_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h1_s), \\\n",
    "                  act_h2), tf.matmul(tf.transpose(h1_s), act_h2_s)))\n",
    "        b2_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1_s, h1_s), \\\n",
    "                   0, True))\n",
    "        b2_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2, act_h2_s), \\\n",
    "                0, True))\n",
    "        \n",
    "        # 세 번째 은닉층\n",
    "        W3_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h2_s), \\\n",
    "                  act_h3), tf.matmul(tf.transpose(h2_s), act_h3_s)))  \n",
    "        b3_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2_s, h2_s), \\\n",
    "                   0, True))  \n",
    "        b3_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3, act_h3_s), \\\n",
    "                 0, True))  \n",
    "        \n",
    "        # 네 번째 은닉층\n",
    "        W4_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h3_s), \\\n",
    "                  act_h4), tf.matmul(tf.transpose(h3_s), act_h4_s)))  \n",
    "        b4_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3_s, h3_s), \\\n",
    "                   0, True))  \n",
    "        b4_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h4, act_h4_s), \\\n",
    "                 0, True))  \n",
    "        \n",
    "        updt = [W1.assign_add(W1_add), b1_i.assign_add(b1_i_add), b1_h.assign_add(b1_h_add),\\\n",
    "                W2.assign_add(W2_add), b2_i.assign_add(b2_i_add), b2_h.assign_add(b2_h_add),\\\n",
    "                W3.assign_add(W3_add), b3_i.assign_add(b3_i_add), b3_h.assign_add(b3_h_add),\\\n",
    "                W4.assign_add(W4_add), b4_i.assign_add(b4_i_add), b4_h.assign_add(b4_h_add)] \n",
    "        \n",
    "        #-------------------------------------------------------------\n",
    "        # 소프트맥스 층을 추가한 분류용-DBN 을 위한 연산과정\n",
    "        #------------------------------------------------------------- \n",
    "        \n",
    "        logits = tf.matmul(act_h4,W_c) + b_c\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr_class).minimize(cost)\n",
    "        correct_pred = tf.equal(tf.argmax(logits,1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        #-------------------------------------------------------------                   \n",
    "        # RBM을 쌓아 올려가며 DBN을 학습하는 텐서플로 그래프 실행   \n",
    "        #-------------------------------------------------------------\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize the variables of the Model\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            \n",
    "            n_batch = int(len(x_train)/batch_size)\n",
    "            # Start the training \n",
    "            for epoch in range(n_epoch):\n",
    "                # Loop over all batches\n",
    "                for i in range(n_batch):\n",
    "                    batch_xs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                    # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                    batch_xs = batch_xs.reshape((-1, 784))\n",
    "                    batch_xs = (batch_xs > 0)*1\n",
    "                    # Run the weight update \n",
    "                    _ = sess.run(updt, feed_dict={x:batch_xs})\n",
    "                    \n",
    "                # Display the running step \n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1))\n",
    "                          \n",
    "            print(\"RBM training Completed !\")\n",
    "        #--------------------------------------------------------------\n",
    "        # 소프트맥스 층을 추가한 분류용-DBN 학습 및 예측\n",
    "        #--------------------------------------------------------------\n",
    "            for i in range(n_iter):\n",
    "                indices = np.random.randint(len(x_train), size=batch_size)\n",
    "                batch_x = x_train[indices]\n",
    "                batch_y = y_train[indices]\n",
    "        \n",
    "                # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                batch_x = batch_x.reshape((-1, 784))\n",
    "                # ++ 레이블 데이터를 원-핫 인코딩\n",
    "                batch_y = np.eye(10)[batch_y]\n",
    "            \n",
    "                # 최적화 과정 실행\n",
    "                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "                if i % 10 == 0:\n",
    "                    # MINIST 훈련용 이미지의 배치에 대한 손실과 정확도를 계산\n",
    "                    tr_loss, tr_acc = sess.run([cost, accuracy], \n",
    "                    \t                    feed_dict={x: batch_x, y: batch_y})\n",
    "                    print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.6f}\".format(tr_loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.5f}\".format(tr_acc))\n",
    "                \n",
    "            print(\"Optimization Finished!\")\n",
    "        \n",
    "            # MINIST 검정용 이미지에 대한 정확도 계산 \n",
    "            print(\"Testing Accuracy:\", \\\n",
    "                sess.run(accuracy, feed_dict={x: x_test.reshape((-1, 784)), #타입 수정\n",
    "                                              y: np.eye(10)[y_test]})) #타입 수정\n",
    "        \n",
    "            sess.close()\n",
    "             \n",
    "        print(\"Hidden Layer 2 Nodes:\", n_hidden2, \"Hidden Layer 3 Nodes:\", n_hidden3, \"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
