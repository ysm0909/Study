{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2926c9c0-55f7-470f-8c7d-dcc984210f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\유승미\\AppData\\Local\\Temp\\ipykernel_33300\\4225343611.py:5: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리를 불러들임 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84a5b0e-4706-4911-abaf-126de1ac24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe447cb-790d-49a4-a9ab-ffe02254b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\유승미\\AppData\\Local\\Temp\\ipykernel_33300\\3390607091.py:125: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.496855, Training Accuracy= 0.21484\n",
      "Iter 10, Minibatch Loss= 2.770917, Training Accuracy= 0.16797\n",
      "Iter 20, Minibatch Loss= 2.072991, Training Accuracy= 0.30859\n",
      "Iter 30, Minibatch Loss= 1.822352, Training Accuracy= 0.41406\n",
      "Iter 40, Minibatch Loss= 1.679083, Training Accuracy= 0.46484\n",
      "Iter 50, Minibatch Loss= 1.405283, Training Accuracy= 0.52734\n",
      "Iter 60, Minibatch Loss= 1.423240, Training Accuracy= 0.53906\n",
      "Iter 70, Minibatch Loss= 1.260945, Training Accuracy= 0.55469\n",
      "Iter 80, Minibatch Loss= 1.236598, Training Accuracy= 0.58594\n",
      "Iter 90, Minibatch Loss= 1.290593, Training Accuracy= 0.55859\n",
      "Iter 100, Minibatch Loss= 1.229035, Training Accuracy= 0.60156\n",
      "Iter 110, Minibatch Loss= 1.243365, Training Accuracy= 0.57031\n",
      "Iter 120, Minibatch Loss= 1.146359, Training Accuracy= 0.63672\n",
      "Iter 130, Minibatch Loss= 1.248140, Training Accuracy= 0.59766\n",
      "Iter 140, Minibatch Loss= 1.112830, Training Accuracy= 0.65625\n",
      "Iter 150, Minibatch Loss= 1.165418, Training Accuracy= 0.63672\n",
      "Iter 160, Minibatch Loss= 1.061589, Training Accuracy= 0.61328\n",
      "Iter 170, Minibatch Loss= 1.077713, Training Accuracy= 0.62500\n",
      "Iter 180, Minibatch Loss= 1.010280, Training Accuracy= 0.64453\n",
      "Iter 190, Minibatch Loss= 1.052304, Training Accuracy= 0.62891\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6467\n",
      "Hidden Layer 2 Nodes: 350 Hidden Layer 3 Nodes: 300 Accuracy: Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.252895, Training Accuracy= 0.09375\n",
      "Iter 10, Minibatch Loss= 3.294083, Training Accuracy= 0.16406\n",
      "Iter 20, Minibatch Loss= 2.445524, Training Accuracy= 0.24219\n",
      "Iter 30, Minibatch Loss= 1.879128, Training Accuracy= 0.35938\n",
      "Iter 40, Minibatch Loss= 1.657572, Training Accuracy= 0.47656\n",
      "Iter 50, Minibatch Loss= 1.458300, Training Accuracy= 0.52344\n",
      "Iter 60, Minibatch Loss= 1.451694, Training Accuracy= 0.50781\n",
      "Iter 70, Minibatch Loss= 0.975478, Training Accuracy= 0.67969\n",
      "Iter 80, Minibatch Loss= 1.316908, Training Accuracy= 0.55859\n",
      "Iter 90, Minibatch Loss= 1.240705, Training Accuracy= 0.55469\n",
      "Iter 100, Minibatch Loss= 1.280842, Training Accuracy= 0.56250\n",
      "Iter 110, Minibatch Loss= 1.292909, Training Accuracy= 0.57422\n",
      "Iter 120, Minibatch Loss= 1.039016, Training Accuracy= 0.62891\n",
      "Iter 130, Minibatch Loss= 0.955467, Training Accuracy= 0.67578\n",
      "Iter 140, Minibatch Loss= 1.119920, Training Accuracy= 0.66016\n",
      "Iter 150, Minibatch Loss= 1.041020, Training Accuracy= 0.62109\n",
      "Iter 160, Minibatch Loss= 1.056851, Training Accuracy= 0.63281\n",
      "Iter 170, Minibatch Loss= 1.048395, Training Accuracy= 0.62500\n",
      "Iter 180, Minibatch Loss= 1.140504, Training Accuracy= 0.60156\n",
      "Iter 190, Minibatch Loss= 0.963608, Training Accuracy= 0.66797\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6609\n",
      "Hidden Layer 2 Nodes: 350 Hidden Layer 3 Nodes: 250 Accuracy: Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.693458, Training Accuracy= 0.16797\n",
      "Iter 10, Minibatch Loss= 2.751535, Training Accuracy= 0.26953\n",
      "Iter 20, Minibatch Loss= 1.996869, Training Accuracy= 0.35938\n",
      "Iter 30, Minibatch Loss= 1.813639, Training Accuracy= 0.35547\n",
      "Iter 40, Minibatch Loss= 1.570021, Training Accuracy= 0.50000\n",
      "Iter 50, Minibatch Loss= 1.525357, Training Accuracy= 0.43359\n",
      "Iter 60, Minibatch Loss= 1.540592, Training Accuracy= 0.43359\n",
      "Iter 70, Minibatch Loss= 1.306276, Training Accuracy= 0.53125\n",
      "Iter 80, Minibatch Loss= 1.354016, Training Accuracy= 0.53516\n",
      "Iter 90, Minibatch Loss= 1.232943, Training Accuracy= 0.53125\n",
      "Iter 100, Minibatch Loss= 1.259679, Training Accuracy= 0.58203\n",
      "Iter 110, Minibatch Loss= 1.374505, Training Accuracy= 0.52734\n",
      "Iter 120, Minibatch Loss= 1.145144, Training Accuracy= 0.61719\n",
      "Iter 130, Minibatch Loss= 1.067336, Training Accuracy= 0.62891\n",
      "Iter 140, Minibatch Loss= 1.123732, Training Accuracy= 0.59375\n",
      "Iter 150, Minibatch Loss= 1.045609, Training Accuracy= 0.64062\n",
      "Iter 160, Minibatch Loss= 1.104459, Training Accuracy= 0.58984\n",
      "Iter 170, Minibatch Loss= 1.111760, Training Accuracy= 0.61719\n",
      "Iter 180, Minibatch Loss= 1.187007, Training Accuracy= 0.60547\n",
      "Iter 190, Minibatch Loss= 1.026628, Training Accuracy= 0.61328\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6326\n",
      "Hidden Layer 2 Nodes: 350 Hidden Layer 3 Nodes: 200 Accuracy: Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.107616, Training Accuracy= 0.09766\n",
      "Iter 10, Minibatch Loss= 2.875249, Training Accuracy= 0.16016\n",
      "Iter 20, Minibatch Loss= 2.219456, Training Accuracy= 0.28906\n",
      "Iter 30, Minibatch Loss= 1.795543, Training Accuracy= 0.35156\n",
      "Iter 40, Minibatch Loss= 1.539944, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.444922, Training Accuracy= 0.47656\n",
      "Iter 60, Minibatch Loss= 1.379347, Training Accuracy= 0.49609\n",
      "Iter 70, Minibatch Loss= 1.497025, Training Accuracy= 0.48828\n",
      "Iter 80, Minibatch Loss= 1.280800, Training Accuracy= 0.55859\n",
      "Iter 90, Minibatch Loss= 1.167305, Training Accuracy= 0.61328\n",
      "Iter 100, Minibatch Loss= 1.122545, Training Accuracy= 0.60938\n",
      "Iter 110, Minibatch Loss= 1.128071, Training Accuracy= 0.57812\n",
      "Iter 120, Minibatch Loss= 1.196440, Training Accuracy= 0.58984\n",
      "Iter 130, Minibatch Loss= 0.954361, Training Accuracy= 0.62891\n",
      "Iter 140, Minibatch Loss= 1.075008, Training Accuracy= 0.58203\n",
      "Iter 150, Minibatch Loss= 1.150648, Training Accuracy= 0.59766\n",
      "Iter 160, Minibatch Loss= 1.072077, Training Accuracy= 0.60938\n",
      "Iter 170, Minibatch Loss= 1.190737, Training Accuracy= 0.58203\n",
      "Iter 180, Minibatch Loss= 0.962454, Training Accuracy= 0.64453\n",
      "Iter 190, Minibatch Loss= 1.159378, Training Accuracy= 0.58203\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6231\n",
      "Hidden Layer 2 Nodes: 350 Hidden Layer 3 Nodes: 150 Accuracy: Tensor(\"Mean_7:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.050061, Training Accuracy= 0.08984\n",
      "Iter 10, Minibatch Loss= 3.545338, Training Accuracy= 0.22266\n",
      "Iter 20, Minibatch Loss= 2.537189, Training Accuracy= 0.32031\n",
      "Iter 30, Minibatch Loss= 2.012567, Training Accuracy= 0.33203\n",
      "Iter 40, Minibatch Loss= 1.697050, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.470136, Training Accuracy= 0.53906\n",
      "Iter 60, Minibatch Loss= 1.344862, Training Accuracy= 0.55859\n",
      "Iter 70, Minibatch Loss= 1.364924, Training Accuracy= 0.47266\n",
      "Iter 80, Minibatch Loss= 1.337533, Training Accuracy= 0.54688\n",
      "Iter 90, Minibatch Loss= 1.178341, Training Accuracy= 0.60156\n",
      "Iter 100, Minibatch Loss= 1.311067, Training Accuracy= 0.55469\n",
      "Iter 110, Minibatch Loss= 1.293232, Training Accuracy= 0.53906\n",
      "Iter 120, Minibatch Loss= 1.252244, Training Accuracy= 0.53906\n",
      "Iter 130, Minibatch Loss= 1.200401, Training Accuracy= 0.57812\n",
      "Iter 140, Minibatch Loss= 1.305558, Training Accuracy= 0.54297\n",
      "Iter 150, Minibatch Loss= 1.240547, Training Accuracy= 0.53125\n",
      "Iter 160, Minibatch Loss= 1.287304, Training Accuracy= 0.54688\n",
      "Iter 170, Minibatch Loss= 1.162206, Training Accuracy= 0.57422\n",
      "Iter 180, Minibatch Loss= 1.187424, Training Accuracy= 0.57422\n",
      "Iter 190, Minibatch Loss= 1.192057, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6021\n",
      "Hidden Layer 2 Nodes: 350 Hidden Layer 3 Nodes: 100 Accuracy: Tensor(\"Mean_9:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.001501, Training Accuracy= 0.05859\n",
      "Iter 10, Minibatch Loss= 3.545758, Training Accuracy= 0.14453\n",
      "Iter 20, Minibatch Loss= 2.382119, Training Accuracy= 0.28125\n",
      "Iter 30, Minibatch Loss= 1.922770, Training Accuracy= 0.39844\n",
      "Iter 40, Minibatch Loss= 1.799784, Training Accuracy= 0.38672\n",
      "Iter 50, Minibatch Loss= 1.572155, Training Accuracy= 0.45703\n",
      "Iter 60, Minibatch Loss= 1.425137, Training Accuracy= 0.51172\n",
      "Iter 70, Minibatch Loss= 1.281353, Training Accuracy= 0.58203\n",
      "Iter 80, Minibatch Loss= 1.259310, Training Accuracy= 0.56250\n",
      "Iter 90, Minibatch Loss= 1.247350, Training Accuracy= 0.57812\n",
      "Iter 100, Minibatch Loss= 1.243997, Training Accuracy= 0.59766\n",
      "Iter 110, Minibatch Loss= 1.065747, Training Accuracy= 0.66016\n",
      "Iter 120, Minibatch Loss= 1.067713, Training Accuracy= 0.65234\n",
      "Iter 130, Minibatch Loss= 1.084576, Training Accuracy= 0.60547\n",
      "Iter 140, Minibatch Loss= 1.045497, Training Accuracy= 0.63281\n",
      "Iter 150, Minibatch Loss= 1.291702, Training Accuracy= 0.54297\n",
      "Iter 160, Minibatch Loss= 1.171489, Training Accuracy= 0.60156\n",
      "Iter 170, Minibatch Loss= 1.069493, Training Accuracy= 0.63281\n",
      "Iter 180, Minibatch Loss= 1.159926, Training Accuracy= 0.61328\n",
      "Iter 190, Minibatch Loss= 1.064326, Training Accuracy= 0.62891\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6421\n",
      "Hidden Layer 2 Nodes: 300 Hidden Layer 3 Nodes: 250 Accuracy: Tensor(\"Mean_11:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.193913, Training Accuracy= 0.08203\n",
      "Iter 10, Minibatch Loss= 3.140975, Training Accuracy= 0.16406\n",
      "Iter 20, Minibatch Loss= 2.217403, Training Accuracy= 0.27344\n",
      "Iter 30, Minibatch Loss= 2.044133, Training Accuracy= 0.36328\n",
      "Iter 40, Minibatch Loss= 1.885267, Training Accuracy= 0.36328\n",
      "Iter 50, Minibatch Loss= 1.569772, Training Accuracy= 0.49219\n",
      "Iter 60, Minibatch Loss= 1.397110, Training Accuracy= 0.47266\n",
      "Iter 70, Minibatch Loss= 1.235154, Training Accuracy= 0.53516\n",
      "Iter 80, Minibatch Loss= 1.312596, Training Accuracy= 0.52734\n",
      "Iter 90, Minibatch Loss= 1.258735, Training Accuracy= 0.59766\n",
      "Iter 100, Minibatch Loss= 1.260457, Training Accuracy= 0.59766\n",
      "Iter 110, Minibatch Loss= 1.094728, Training Accuracy= 0.60938\n",
      "Iter 120, Minibatch Loss= 1.147097, Training Accuracy= 0.59766\n",
      "Iter 130, Minibatch Loss= 1.227867, Training Accuracy= 0.58203\n",
      "Iter 140, Minibatch Loss= 1.054525, Training Accuracy= 0.64062\n",
      "Iter 150, Minibatch Loss= 1.120426, Training Accuracy= 0.61328\n",
      "Iter 160, Minibatch Loss= 1.133146, Training Accuracy= 0.62109\n",
      "Iter 170, Minibatch Loss= 0.948374, Training Accuracy= 0.71094\n",
      "Iter 180, Minibatch Loss= 1.101675, Training Accuracy= 0.63281\n",
      "Iter 190, Minibatch Loss= 1.068437, Training Accuracy= 0.62109\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6469\n",
      "Hidden Layer 2 Nodes: 300 Hidden Layer 3 Nodes: 200 Accuracy: Tensor(\"Mean_13:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.908581, Training Accuracy= 0.19922\n",
      "Iter 10, Minibatch Loss= 3.189919, Training Accuracy= 0.28125\n",
      "Iter 20, Minibatch Loss= 2.165845, Training Accuracy= 0.32031\n",
      "Iter 30, Minibatch Loss= 2.131470, Training Accuracy= 0.27734\n",
      "Iter 40, Minibatch Loss= 1.727637, Training Accuracy= 0.42578\n",
      "Iter 50, Minibatch Loss= 1.635557, Training Accuracy= 0.44531\n",
      "Iter 60, Minibatch Loss= 1.501917, Training Accuracy= 0.44531\n",
      "Iter 70, Minibatch Loss= 1.469922, Training Accuracy= 0.49219\n",
      "Iter 80, Minibatch Loss= 1.403404, Training Accuracy= 0.51172\n",
      "Iter 90, Minibatch Loss= 1.235238, Training Accuracy= 0.57422\n",
      "Iter 100, Minibatch Loss= 1.189205, Training Accuracy= 0.58594\n",
      "Iter 110, Minibatch Loss= 1.116780, Training Accuracy= 0.57422\n",
      "Iter 120, Minibatch Loss= 1.181911, Training Accuracy= 0.56641\n",
      "Iter 130, Minibatch Loss= 1.167695, Training Accuracy= 0.60547\n",
      "Iter 140, Minibatch Loss= 1.317728, Training Accuracy= 0.52734\n",
      "Iter 150, Minibatch Loss= 1.193649, Training Accuracy= 0.58594\n",
      "Iter 160, Minibatch Loss= 1.188312, Training Accuracy= 0.57812\n",
      "Iter 170, Minibatch Loss= 1.352085, Training Accuracy= 0.53906\n",
      "Iter 180, Minibatch Loss= 1.032026, Training Accuracy= 0.64453\n",
      "Iter 190, Minibatch Loss= 1.120178, Training Accuracy= 0.62891\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6066\n",
      "Hidden Layer 2 Nodes: 300 Hidden Layer 3 Nodes: 150 Accuracy: Tensor(\"Mean_15:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 6.142163, Training Accuracy= 0.09766\n",
      "Iter 10, Minibatch Loss= 3.352788, Training Accuracy= 0.23047\n",
      "Iter 20, Minibatch Loss= 2.099196, Training Accuracy= 0.32422\n",
      "Iter 30, Minibatch Loss= 1.814284, Training Accuracy= 0.38672\n",
      "Iter 40, Minibatch Loss= 1.631720, Training Accuracy= 0.43359\n",
      "Iter 50, Minibatch Loss= 1.568959, Training Accuracy= 0.47656\n",
      "Iter 60, Minibatch Loss= 1.428920, Training Accuracy= 0.50781\n",
      "Iter 70, Minibatch Loss= 1.419109, Training Accuracy= 0.50781\n",
      "Iter 80, Minibatch Loss= 1.354262, Training Accuracy= 0.49219\n",
      "Iter 90, Minibatch Loss= 1.339135, Training Accuracy= 0.56250\n",
      "Iter 100, Minibatch Loss= 1.203230, Training Accuracy= 0.54688\n",
      "Iter 110, Minibatch Loss= 1.249849, Training Accuracy= 0.51953\n",
      "Iter 120, Minibatch Loss= 1.287781, Training Accuracy= 0.53125\n",
      "Iter 130, Minibatch Loss= 1.134056, Training Accuracy= 0.60938\n",
      "Iter 140, Minibatch Loss= 1.240200, Training Accuracy= 0.55859\n",
      "Iter 150, Minibatch Loss= 1.201418, Training Accuracy= 0.56641\n",
      "Iter 160, Minibatch Loss= 1.242137, Training Accuracy= 0.59766\n",
      "Iter 170, Minibatch Loss= 1.183103, Training Accuracy= 0.59766\n",
      "Iter 180, Minibatch Loss= 1.268329, Training Accuracy= 0.59375\n",
      "Iter 190, Minibatch Loss= 1.065732, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5844\n",
      "Hidden Layer 2 Nodes: 300 Hidden Layer 3 Nodes: 100 Accuracy: Tensor(\"Mean_17:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.849341, Training Accuracy= 0.09375\n",
      "Iter 10, Minibatch Loss= 3.892441, Training Accuracy= 0.17188\n",
      "Iter 20, Minibatch Loss= 2.335209, Training Accuracy= 0.27344\n",
      "Iter 30, Minibatch Loss= 1.969662, Training Accuracy= 0.30469\n",
      "Iter 40, Minibatch Loss= 1.816607, Training Accuracy= 0.37891\n",
      "Iter 50, Minibatch Loss= 1.540226, Training Accuracy= 0.44922\n",
      "Iter 60, Minibatch Loss= 1.613243, Training Accuracy= 0.41016\n",
      "Iter 70, Minibatch Loss= 1.408670, Training Accuracy= 0.49219\n",
      "Iter 80, Minibatch Loss= 1.394163, Training Accuracy= 0.49219\n",
      "Iter 90, Minibatch Loss= 1.321578, Training Accuracy= 0.52344\n",
      "Iter 100, Minibatch Loss= 1.376215, Training Accuracy= 0.51562\n",
      "Iter 110, Minibatch Loss= 1.301007, Training Accuracy= 0.54297\n",
      "Iter 120, Minibatch Loss= 1.395842, Training Accuracy= 0.50391\n",
      "Iter 130, Minibatch Loss= 1.233254, Training Accuracy= 0.57422\n",
      "Iter 140, Minibatch Loss= 1.315298, Training Accuracy= 0.53516\n",
      "Iter 150, Minibatch Loss= 1.184381, Training Accuracy= 0.57031\n",
      "Iter 160, Minibatch Loss= 1.340913, Training Accuracy= 0.52734\n",
      "Iter 170, Minibatch Loss= 1.263231, Training Accuracy= 0.52344\n",
      "Iter 180, Minibatch Loss= 1.133283, Training Accuracy= 0.58984\n",
      "Iter 190, Minibatch Loss= 1.198992, Training Accuracy= 0.60156\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5819\n",
      "Hidden Layer 2 Nodes: 250 Hidden Layer 3 Nodes: 200 Accuracy: Tensor(\"Mean_19:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.456814, Training Accuracy= 0.03516\n",
      "Iter 10, Minibatch Loss= 3.027184, Training Accuracy= 0.11328\n",
      "Iter 20, Minibatch Loss= 2.098674, Training Accuracy= 0.30078\n",
      "Iter 30, Minibatch Loss= 1.705910, Training Accuracy= 0.44922\n",
      "Iter 40, Minibatch Loss= 1.599912, Training Accuracy= 0.41016\n",
      "Iter 50, Minibatch Loss= 1.510729, Training Accuracy= 0.48438\n",
      "Iter 60, Minibatch Loss= 1.617162, Training Accuracy= 0.46484\n",
      "Iter 70, Minibatch Loss= 1.379258, Training Accuracy= 0.53125\n",
      "Iter 80, Minibatch Loss= 1.422898, Training Accuracy= 0.52344\n",
      "Iter 90, Minibatch Loss= 1.312389, Training Accuracy= 0.54688\n",
      "Iter 100, Minibatch Loss= 1.225888, Training Accuracy= 0.56250\n",
      "Iter 110, Minibatch Loss= 1.295844, Training Accuracy= 0.56641\n",
      "Iter 120, Minibatch Loss= 1.261709, Training Accuracy= 0.56641\n",
      "Iter 130, Minibatch Loss= 1.360803, Training Accuracy= 0.53125\n",
      "Iter 140, Minibatch Loss= 1.342053, Training Accuracy= 0.53125\n",
      "Iter 150, Minibatch Loss= 1.093826, Training Accuracy= 0.63281\n",
      "Iter 160, Minibatch Loss= 1.032985, Training Accuracy= 0.61719\n",
      "Iter 170, Minibatch Loss= 1.147960, Training Accuracy= 0.60156\n",
      "Iter 180, Minibatch Loss= 1.226855, Training Accuracy= 0.55469\n",
      "Iter 190, Minibatch Loss= 1.271252, Training Accuracy= 0.54297\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5991\n",
      "Hidden Layer 2 Nodes: 250 Hidden Layer 3 Nodes: 150 Accuracy: Tensor(\"Mean_21:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.098163, Training Accuracy= 0.11328\n",
      "Iter 10, Minibatch Loss= 2.499612, Training Accuracy= 0.17188\n",
      "Iter 20, Minibatch Loss= 2.079881, Training Accuracy= 0.21875\n",
      "Iter 30, Minibatch Loss= 1.666820, Training Accuracy= 0.42188\n",
      "Iter 40, Minibatch Loss= 1.488570, Training Accuracy= 0.44141\n",
      "Iter 50, Minibatch Loss= 1.505238, Training Accuracy= 0.48047\n",
      "Iter 60, Minibatch Loss= 1.493294, Training Accuracy= 0.44531\n",
      "Iter 70, Minibatch Loss= 1.337908, Training Accuracy= 0.51953\n",
      "Iter 80, Minibatch Loss= 1.368625, Training Accuracy= 0.52344\n",
      "Iter 90, Minibatch Loss= 1.264890, Training Accuracy= 0.58984\n",
      "Iter 100, Minibatch Loss= 1.288892, Training Accuracy= 0.51172\n",
      "Iter 110, Minibatch Loss= 1.257160, Training Accuracy= 0.54297\n",
      "Iter 120, Minibatch Loss= 1.159653, Training Accuracy= 0.60156\n",
      "Iter 130, Minibatch Loss= 1.227883, Training Accuracy= 0.52734\n",
      "Iter 140, Minibatch Loss= 1.121162, Training Accuracy= 0.63281\n",
      "Iter 150, Minibatch Loss= 1.111182, Training Accuracy= 0.58203\n",
      "Iter 160, Minibatch Loss= 1.111170, Training Accuracy= 0.58594\n",
      "Iter 170, Minibatch Loss= 1.152635, Training Accuracy= 0.59766\n",
      "Iter 180, Minibatch Loss= 1.349463, Training Accuracy= 0.53906\n",
      "Iter 190, Minibatch Loss= 1.134575, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6052\n",
      "Hidden Layer 2 Nodes: 250 Hidden Layer 3 Nodes: 100 Accuracy: Tensor(\"Mean_23:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 7.009792, Training Accuracy= 0.06250\n",
      "Iter 10, Minibatch Loss= 3.787624, Training Accuracy= 0.25000\n",
      "Iter 20, Minibatch Loss= 2.679507, Training Accuracy= 0.15234\n",
      "Iter 30, Minibatch Loss= 2.025153, Training Accuracy= 0.35156\n",
      "Iter 40, Minibatch Loss= 1.712935, Training Accuracy= 0.44531\n",
      "Iter 50, Minibatch Loss= 1.759031, Training Accuracy= 0.43359\n",
      "Iter 60, Minibatch Loss= 1.498108, Training Accuracy= 0.53516\n",
      "Iter 70, Minibatch Loss= 1.386993, Training Accuracy= 0.55469\n",
      "Iter 80, Minibatch Loss= 1.249372, Training Accuracy= 0.55469\n",
      "Iter 90, Minibatch Loss= 1.369644, Training Accuracy= 0.49609\n",
      "Iter 100, Minibatch Loss= 1.238871, Training Accuracy= 0.55469\n",
      "Iter 110, Minibatch Loss= 1.159148, Training Accuracy= 0.61719\n",
      "Iter 120, Minibatch Loss= 1.323365, Training Accuracy= 0.57422\n",
      "Iter 130, Minibatch Loss= 1.085652, Training Accuracy= 0.63281\n",
      "Iter 140, Minibatch Loss= 1.216133, Training Accuracy= 0.57812\n",
      "Iter 150, Minibatch Loss= 1.134887, Training Accuracy= 0.58984\n",
      "Iter 160, Minibatch Loss= 1.142532, Training Accuracy= 0.58203\n",
      "Iter 170, Minibatch Loss= 1.243592, Training Accuracy= 0.59766\n",
      "Iter 180, Minibatch Loss= 1.110802, Training Accuracy= 0.61328\n",
      "Iter 190, Minibatch Loss= 1.165126, Training Accuracy= 0.58203\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6152\n",
      "Hidden Layer 2 Nodes: 200 Hidden Layer 3 Nodes: 150 Accuracy: Tensor(\"Mean_25:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 5.300416, Training Accuracy= 0.15234\n",
      "Iter 10, Minibatch Loss= 2.724443, Training Accuracy= 0.10547\n",
      "Iter 20, Minibatch Loss= 2.089152, Training Accuracy= 0.26562\n",
      "Iter 30, Minibatch Loss= 1.579032, Training Accuracy= 0.48828\n",
      "Iter 40, Minibatch Loss= 1.456070, Training Accuracy= 0.51172\n",
      "Iter 50, Minibatch Loss= 1.309860, Training Accuracy= 0.57031\n",
      "Iter 60, Minibatch Loss= 1.453981, Training Accuracy= 0.52344\n",
      "Iter 70, Minibatch Loss= 1.143891, Training Accuracy= 0.64844\n",
      "Iter 80, Minibatch Loss= 1.230939, Training Accuracy= 0.55469\n",
      "Iter 90, Minibatch Loss= 1.365830, Training Accuracy= 0.52344\n",
      "Iter 100, Minibatch Loss= 1.220827, Training Accuracy= 0.57812\n",
      "Iter 110, Minibatch Loss= 1.146599, Training Accuracy= 0.60547\n",
      "Iter 120, Minibatch Loss= 1.167162, Training Accuracy= 0.62891\n",
      "Iter 130, Minibatch Loss= 1.237084, Training Accuracy= 0.57422\n",
      "Iter 140, Minibatch Loss= 1.296261, Training Accuracy= 0.54688\n",
      "Iter 150, Minibatch Loss= 1.304118, Training Accuracy= 0.55859\n",
      "Iter 160, Minibatch Loss= 1.142842, Training Accuracy= 0.58984\n",
      "Iter 170, Minibatch Loss= 1.121662, Training Accuracy= 0.60156\n",
      "Iter 180, Minibatch Loss= 1.212052, Training Accuracy= 0.53906\n",
      "Iter 190, Minibatch Loss= 1.138269, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6049\n",
      "Hidden Layer 2 Nodes: 200 Hidden Layer 3 Nodes: 100 Accuracy: Tensor(\"Mean_27:0\", shape=(), dtype=float32)\n",
      "Epoch: 0001\n",
      "Epoch: 0002\n",
      "Epoch: 0003\n",
      "Epoch: 0004\n",
      "Epoch: 0005\n",
      "Epoch: 0006\n",
      "Epoch: 0007\n",
      "Epoch: 0008\n",
      "Epoch: 0009\n",
      "Epoch: 0010\n",
      "Epoch: 0011\n",
      "Epoch: 0012\n",
      "Epoch: 0013\n",
      "Epoch: 0014\n",
      "Epoch: 0015\n",
      "Epoch: 0016\n",
      "Epoch: 0017\n",
      "Epoch: 0018\n",
      "Epoch: 0019\n",
      "Epoch: 0020\n",
      "Epoch: 0021\n",
      "Epoch: 0022\n",
      "Epoch: 0023\n",
      "Epoch: 0024\n",
      "Epoch: 0025\n",
      "Epoch: 0026\n",
      "Epoch: 0027\n",
      "Epoch: 0028\n",
      "Epoch: 0029\n",
      "Epoch: 0030\n",
      "Epoch: 0031\n",
      "Epoch: 0032\n",
      "Epoch: 0033\n",
      "Epoch: 0034\n",
      "Epoch: 0035\n",
      "Epoch: 0036\n",
      "Epoch: 0037\n",
      "Epoch: 0038\n",
      "Epoch: 0039\n",
      "Epoch: 0040\n",
      "Epoch: 0041\n",
      "Epoch: 0042\n",
      "Epoch: 0043\n",
      "Epoch: 0044\n",
      "Epoch: 0045\n",
      "Epoch: 0046\n",
      "Epoch: 0047\n",
      "Epoch: 0048\n",
      "Epoch: 0049\n",
      "Epoch: 0050\n",
      "Epoch: 0051\n",
      "Epoch: 0052\n",
      "Epoch: 0053\n",
      "Epoch: 0054\n",
      "Epoch: 0055\n",
      "Epoch: 0056\n",
      "Epoch: 0057\n",
      "Epoch: 0058\n",
      "Epoch: 0059\n",
      "Epoch: 0060\n",
      "Epoch: 0061\n",
      "Epoch: 0062\n",
      "Epoch: 0063\n",
      "Epoch: 0064\n",
      "Epoch: 0065\n",
      "Epoch: 0066\n",
      "Epoch: 0067\n",
      "Epoch: 0068\n",
      "Epoch: 0069\n",
      "Epoch: 0070\n",
      "Epoch: 0071\n",
      "Epoch: 0072\n",
      "Epoch: 0073\n",
      "Epoch: 0074\n",
      "Epoch: 0075\n",
      "Epoch: 0076\n",
      "Epoch: 0077\n",
      "Epoch: 0078\n",
      "Epoch: 0079\n",
      "Epoch: 0080\n",
      "Epoch: 0081\n",
      "Epoch: 0082\n",
      "Epoch: 0083\n",
      "Epoch: 0084\n",
      "Epoch: 0085\n",
      "Epoch: 0086\n",
      "Epoch: 0087\n",
      "Epoch: 0088\n",
      "Epoch: 0089\n",
      "Epoch: 0090\n",
      "Epoch: 0091\n",
      "Epoch: 0092\n",
      "Epoch: 0093\n",
      "Epoch: 0094\n",
      "Epoch: 0095\n",
      "Epoch: 0096\n",
      "Epoch: 0097\n",
      "Epoch: 0098\n",
      "Epoch: 0099\n",
      "Epoch: 0100\n",
      "Epoch: 0101\n",
      "Epoch: 0102\n",
      "Epoch: 0103\n",
      "Epoch: 0104\n",
      "Epoch: 0105\n",
      "Epoch: 0106\n",
      "Epoch: 0107\n",
      "Epoch: 0108\n",
      "Epoch: 0109\n",
      "Epoch: 0110\n",
      "Epoch: 0111\n",
      "Epoch: 0112\n",
      "Epoch: 0113\n",
      "Epoch: 0114\n",
      "Epoch: 0115\n",
      "Epoch: 0116\n",
      "Epoch: 0117\n",
      "Epoch: 0118\n",
      "Epoch: 0119\n",
      "Epoch: 0120\n",
      "Epoch: 0121\n",
      "Epoch: 0122\n",
      "Epoch: 0123\n",
      "Epoch: 0124\n",
      "Epoch: 0125\n",
      "Epoch: 0126\n",
      "Epoch: 0127\n",
      "Epoch: 0128\n",
      "Epoch: 0129\n",
      "Epoch: 0130\n",
      "Epoch: 0131\n",
      "Epoch: 0132\n",
      "Epoch: 0133\n",
      "Epoch: 0134\n",
      "Epoch: 0135\n",
      "Epoch: 0136\n",
      "Epoch: 0137\n",
      "Epoch: 0138\n",
      "Epoch: 0139\n",
      "Epoch: 0140\n",
      "Epoch: 0141\n",
      "Epoch: 0142\n",
      "Epoch: 0143\n",
      "Epoch: 0144\n",
      "Epoch: 0145\n",
      "Epoch: 0146\n",
      "Epoch: 0147\n",
      "Epoch: 0148\n",
      "Epoch: 0149\n",
      "Epoch: 0150\n",
      "Epoch: 0151\n",
      "Epoch: 0152\n",
      "Epoch: 0153\n",
      "Epoch: 0154\n",
      "Epoch: 0155\n",
      "Epoch: 0156\n",
      "Epoch: 0157\n",
      "Epoch: 0158\n",
      "Epoch: 0159\n",
      "Epoch: 0160\n",
      "Epoch: 0161\n",
      "Epoch: 0162\n",
      "Epoch: 0163\n",
      "Epoch: 0164\n",
      "Epoch: 0165\n",
      "Epoch: 0166\n",
      "Epoch: 0167\n",
      "Epoch: 0168\n",
      "Epoch: 0169\n",
      "Epoch: 0170\n",
      "Epoch: 0171\n",
      "Epoch: 0172\n",
      "Epoch: 0173\n",
      "Epoch: 0174\n",
      "Epoch: 0175\n",
      "Epoch: 0176\n",
      "Epoch: 0177\n",
      "Epoch: 0178\n",
      "Epoch: 0179\n",
      "Epoch: 0180\n",
      "Epoch: 0181\n",
      "Epoch: 0182\n",
      "Epoch: 0183\n",
      "Epoch: 0184\n",
      "Epoch: 0185\n",
      "Epoch: 0186\n",
      "Epoch: 0187\n",
      "Epoch: 0188\n",
      "Epoch: 0189\n",
      "Epoch: 0190\n",
      "Epoch: 0191\n",
      "Epoch: 0192\n",
      "Epoch: 0193\n",
      "Epoch: 0194\n",
      "Epoch: 0195\n",
      "Epoch: 0196\n",
      "Epoch: 0197\n",
      "Epoch: 0198\n",
      "Epoch: 0199\n",
      "Epoch: 0200\n",
      "RBM training Completed !\n",
      "Iter 0, Minibatch Loss= 4.323933, Training Accuracy= 0.21875\n",
      "Iter 10, Minibatch Loss= 2.952973, Training Accuracy= 0.23828\n",
      "Iter 20, Minibatch Loss= 1.917840, Training Accuracy= 0.34766\n",
      "Iter 30, Minibatch Loss= 1.791660, Training Accuracy= 0.37891\n",
      "Iter 40, Minibatch Loss= 1.561880, Training Accuracy= 0.43750\n",
      "Iter 50, Minibatch Loss= 1.541189, Training Accuracy= 0.46484\n",
      "Iter 60, Minibatch Loss= 1.554678, Training Accuracy= 0.46094\n",
      "Iter 70, Minibatch Loss= 1.314004, Training Accuracy= 0.55859\n",
      "Iter 80, Minibatch Loss= 1.449943, Training Accuracy= 0.47656\n",
      "Iter 90, Minibatch Loss= 1.290376, Training Accuracy= 0.57031\n",
      "Iter 100, Minibatch Loss= 1.371195, Training Accuracy= 0.55469\n",
      "Iter 110, Minibatch Loss= 1.269560, Training Accuracy= 0.54688\n",
      "Iter 120, Minibatch Loss= 1.394497, Training Accuracy= 0.54297\n",
      "Iter 130, Minibatch Loss= 1.236826, Training Accuracy= 0.60547\n",
      "Iter 140, Minibatch Loss= 1.247370, Training Accuracy= 0.58984\n",
      "Iter 150, Minibatch Loss= 1.196399, Training Accuracy= 0.59766\n",
      "Iter 160, Minibatch Loss= 1.286542, Training Accuracy= 0.50391\n",
      "Iter 170, Minibatch Loss= 1.192519, Training Accuracy= 0.58203\n",
      "Iter 180, Minibatch Loss= 1.149704, Training Accuracy= 0.58984\n",
      "Iter 190, Minibatch Loss= 1.275631, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5854\n",
      "Hidden Layer 2 Nodes: 150 Hidden Layer 3 Nodes: 100 Accuracy: Tensor(\"Mean_29:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치를 통한 두 번째와 세 번째 은닉층의 노드 수 탐색\n",
    "for n_hidden2 in range(350, 149, -50): # 350부터 150까지 50씩 감소\n",
    "    for n_hidden3 in range(300, 99, -50): # 300부터 100까지 50씩 감소\n",
    "        if n_hidden2 > n_hidden3: # 히든2가 히든3보다 클 때만 실행\n",
    "            # 학습 관련 매개변수 및 모델 구조 정의\n",
    "            n_input = 784\n",
    "            n_hidden1 = 400\n",
    "            n_hidden4 = 50\n",
    "            display_step = 1\n",
    "            n_epoch = 200\n",
    "            batch_size = 256\n",
    "            lr_rbm = tf.constant(0.001, tf.float32)\n",
    "            lr_class = tf.constant(0.01, tf.float32)\n",
    "            n_class = 10\n",
    "            n_iter = 200\n",
    "    \n",
    "            # 입력 및 출력 정의\n",
    "            x = tf.placeholder(tf.float32, [None, n_input], name=\"x\")\n",
    "            y = tf.placeholder(tf.float32, [None, 10], name=\"y\")\n",
    "    \n",
    "            # 첫 번째 은닉층 가중치 및 편향 정의\n",
    "            W1 = tf.Variable(tf.random_normal([n_input, n_hidden1], 0.01), name=\"W1\")\n",
    "            b1_h = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b1_h\"))\n",
    "            b1_i = tf.Variable(tf.zeros([1, n_input], tf.float32, name=\"b1_i\"))\n",
    "    \n",
    "            # 두 번째 은닉층 가중치 및 편향 정의\n",
    "            W2 = tf.Variable(tf.random_normal([n_hidden1, n_hidden2], 0.01), name=\"W2\")\n",
    "            b2_h = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b2_h\"))\n",
    "            b2_i = tf.Variable(tf.zeros([1, n_hidden1], tf.float32, name=\"b2_i\"))\n",
    "    \n",
    "            # 세 번째 은닉층 가중치 및 편향 정의\n",
    "            W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden3], 0.01), name=\"W3\")\n",
    "            b3_h = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b3_h\"))\n",
    "            b3_i = tf.Variable(tf.zeros([1, n_hidden2], tf.float32, name=\"b3_i\"))\n",
    "    \n",
    "            # 네 번째 은닉층 가중치 및 편향 정의\n",
    "            W4 = tf.Variable(tf.random_normal([n_hidden3, n_hidden4], 0.01), name=\"W4\")\n",
    "            b4_h = tf.Variable(tf.zeros([1, n_hidden4], tf.float32, name=\"b4_h\"))\n",
    "            b4_i = tf.Variable(tf.zeros([1, n_hidden3], tf.float32, name=\"b4_i\"))\n",
    "    \n",
    "            # 라벨층 가중치 및 편향 정의\n",
    "            W_c = tf.Variable(tf.random_normal([n_hidden4, n_class], 0.01), name=\"W_c\")\n",
    "            b_c = tf.Variable(tf.zeros([1, n_class], tf.float32, name=\"b_c\"))\n",
    "    \n",
    "            # 확률을 이산 상태, 즉 0과 1로 변환함 \n",
    "            def binary(prob):\n",
    "                return tf.floor(prob + tf.random_uniform(tf.shape(prob), 0, 1))\n",
    "            \n",
    "            # Gibbs 표본추출 단계\n",
    "            def cd_step(x_k,W,b_h,b_i):\n",
    "                h_k = binary(tf.sigmoid(tf.matmul(x_k, W) + b_h)) \n",
    "                x_k = binary(tf.sigmoid(tf.matmul(h_k, tf.transpose(W)) + b_i))\n",
    "                return x_k\n",
    "            \n",
    "            # 표본추출 단계 실행     \n",
    "            def cd_gibbs(k,x_k,W,b_h,b_i):\n",
    "                for i in range(k):\n",
    "                    x_out = cd_step(x_k,W,b_h,b_i) \n",
    "                # k 반복 후에 깁스 표본을 반환함\n",
    "                return x_out\n",
    "            \n",
    "            # 4개의 은닉층을 갖는 DBN에 대한 CD-2 알고리즘\n",
    "            # 1. 현재 입력값을 기반으로 깁스 표본추출을 통해 새로운 입력값 x_s를 구함\n",
    "            # 2. 새로운 x_s를 기반으로 새로운 은닉노드 값 h_s를 구함    \n",
    "            x_s = cd_gibbs(2,x,W1,b1_h,b1_i) \n",
    "            act_h1_s = binary(tf.sigmoid(tf.matmul(x_s, W1) + b1_h)) \n",
    "            h1_s = cd_gibbs(2,act_h1_s,W2,b2_h,b2_i) \n",
    "            act_h2_s = binary(tf.sigmoid(tf.matmul(h1_s, W2) + b2_h)) \n",
    "            h2_s = cd_gibbs(2, act_h2_s, W3, b3_h, b3_i)  \n",
    "            act_h3_s = binary(tf.sigmoid(tf.matmul(h2_s, W3) + b3_h))\n",
    "            h3_s = cd_gibbs(2, act_h3_s, W4, b4_h, b4_i)  \n",
    "            act_h4_s = binary(tf.sigmoid(tf.matmul(h3_s, W4) + b4_h))\n",
    "            \n",
    "            # 입력값이 주어질 때 은닉노드 값 h를 구함\n",
    "            act_h1 = tf.sigmoid(tf.matmul(x, W1) + b1_h) \n",
    "            act_h2 = tf.sigmoid(tf.matmul(act_h1_s, W2) + b2_h)\n",
    "            act_h3 = tf.sigmoid(tf.matmul(act_h2_s, W3) + b3_h) \n",
    "            act_h4 = tf.sigmoid(tf.matmul(act_h3_s, W4) + b4_h) \n",
    "            \n",
    "            # 경사 하강법을 이용한 가중치 및 편향 업데이트 \n",
    "            size_batch = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "            # 첫 번째 은닉층\n",
    "            W1_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(x), \\\n",
    "                      act_h1), tf.matmul(tf.transpose(x_s), act_h1_s)))\n",
    "            b1_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(x, x_s), \\\n",
    "                       0, True))\n",
    "            b1_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1, act_h1_s), \\\n",
    "                       0, True))\n",
    "            \n",
    "            # 두 번째 은닉층\n",
    "            W2_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h1_s), \\\n",
    "                      act_h2), tf.matmul(tf.transpose(h1_s), act_h2_s)))\n",
    "            b2_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h1_s, h1_s), \\\n",
    "                       0, True))\n",
    "            b2_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2, act_h2_s), \\\n",
    "                    0, True))\n",
    "            \n",
    "            # 세 번째 은닉층\n",
    "            W3_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h2_s), \\\n",
    "                      act_h3), tf.matmul(tf.transpose(h2_s), act_h3_s)))  \n",
    "            b3_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h2_s, h2_s), \\\n",
    "                       0, True))  \n",
    "            b3_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3, act_h3_s), \\\n",
    "                     0, True))  \n",
    "            \n",
    "            # 네 번째 은닉층\n",
    "            W4_add  = tf.multiply(lr_rbm/size_batch, tf.subtract(tf.matmul(tf.transpose(act_h3_s), \\\n",
    "                      act_h4), tf.matmul(tf.transpose(h3_s), act_h4_s)))  \n",
    "            b4_i_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h3_s, h3_s), \\\n",
    "                       0, True))  \n",
    "            b4_h_add = tf.multiply(lr_rbm/size_batch, tf.reduce_sum(tf.subtract(act_h4, act_h4_s), \\\n",
    "                     0, True))  \n",
    "            \n",
    "            updt = [W1.assign_add(W1_add), b1_i.assign_add(b1_i_add), b1_h.assign_add(b1_h_add),\\\n",
    "                    W2.assign_add(W2_add), b2_i.assign_add(b2_i_add), b2_h.assign_add(b2_h_add),\\\n",
    "                    W3.assign_add(W3_add), b3_i.assign_add(b3_i_add), b3_h.assign_add(b3_h_add),\\\n",
    "                    W4.assign_add(W4_add), b4_i.assign_add(b4_i_add), b4_h.assign_add(b4_h_add)] \n",
    "            \n",
    "            #-------------------------------------------------------------\n",
    "            # 소프트맥스 층을 추가한 분류용-DBN 을 위한 연산과정\n",
    "            #------------------------------------------------------------- \n",
    "            \n",
    "            logits = tf.matmul(act_h4,W_c) + b_c\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=lr_class).minimize(cost)\n",
    "            correct_pred = tf.equal(tf.argmax(logits,1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "            #-------------------------------------------------------------                   \n",
    "            # RBM을 쌓아 올려가며 DBN을 학습하는 텐서플로 그래프 실행   \n",
    "            #-------------------------------------------------------------\n",
    "            with tf.Session() as sess:\n",
    "                # Initialize the variables of the Model\n",
    "                init = tf.global_variables_initializer()\n",
    "                sess.run(init)\n",
    "                \n",
    "                n_batch = int(len(x_train)/batch_size)\n",
    "                # Start the training \n",
    "                for epoch in range(n_epoch):\n",
    "                    # Loop over all batches\n",
    "                    for i in range(n_batch):\n",
    "                        batch_xs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                        # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                        batch_xs = batch_xs.reshape((-1, 784))\n",
    "                        batch_xs = (batch_xs > 0)*1\n",
    "                        # Run the weight update \n",
    "                        _ = sess.run(updt, feed_dict={x:batch_xs})\n",
    "                        \n",
    "                    # Display the running step \n",
    "                    if epoch % display_step == 0:\n",
    "                        print(\"Epoch:\", '%04d' % (epoch+1))\n",
    "                              \n",
    "                print(\"RBM training Completed !\")\n",
    "            #--------------------------------------------------------------\n",
    "            # 소프트맥스 층을 추가한 분류용-DBN 학습 및 예측\n",
    "            #--------------------------------------------------------------\n",
    "                for i in range(n_iter):\n",
    "                    indices = np.random.randint(len(x_train), size=batch_size)\n",
    "                    batch_x = x_train[indices]\n",
    "                    batch_y = y_train[indices]\n",
    "            \n",
    "                    # ++ 이미지 데이터를 784차원 벡터로 평탄화\n",
    "                    batch_x = batch_x.reshape((-1, 784))\n",
    "                    # ++ 레이블 데이터를 원-핫 인코딩\n",
    "                    batch_y = np.eye(10)[batch_y]\n",
    "                \n",
    "                    # 최적화 과정 실행\n",
    "                    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "                    if i % 10 == 0:\n",
    "                        # MINIST 훈련용 이미지의 배치에 대한 손실과 정확도를 계산\n",
    "                        tr_loss, tr_acc = sess.run([cost, accuracy], \n",
    "                        \t                    feed_dict={x: batch_x, y: batch_y})\n",
    "                        print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                              \"{:.6f}\".format(tr_loss) + \", Training Accuracy= \" + \\\n",
    "                              \"{:.5f}\".format(tr_acc))\n",
    "                    \n",
    "                print(\"Optimization Finished!\")\n",
    "            \n",
    "                # MINIST 검정용 이미지에 대한 정확도 계산 \n",
    "                print(\"Testing Accuracy:\", \\\n",
    "                    sess.run(accuracy, feed_dict={x: x_test.reshape((-1, 784)), #타입 수정\n",
    "                                                  y: np.eye(10)[y_test]})) #타입 수정\n",
    "            \n",
    "                sess.close()\n",
    "                 \n",
    "            print(\"Hidden Layer 2 Nodes:\", n_hidden2, \"Hidden Layer 3 Nodes:\", n_hidden3, \"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
